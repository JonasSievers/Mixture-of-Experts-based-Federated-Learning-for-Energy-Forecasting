{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "from utils.modelgenerator import *\n",
    "from utils.modelhandler import *\n",
    "from utils.datahandler import *\n",
    "\n",
    "#Get data \n",
    "cwd = os.path.normpath(os.getcwd())\n",
    "df = pd.read_csv(cwd+'/data/df_with_final_features.csv', index_col='Date') #df = pd.read_csv('user5.csv')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "#df = df[['User5', 'temp', 'rhum']]\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df_array = []\n",
    "for idx in range(30):\n",
    "    df_array.append(df[[f'User{idx+1}', 'temp', 'rhum', 'wspd', 'PC1', 'hour sin', 'hour cos', f'User{idx+1}_lag_24hrs']])\n",
    "\n",
    "#df_array[3].head(3)\n",
    "\n",
    "#Train, Validation and Test datasets\n",
    "sequence_length = 25\n",
    "batch_size = 16\n",
    "num_features = df_array[0].shape[1]\n",
    "\n",
    "dh = Datahandler()\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "#Create Train, Validation and Test datasets\n",
    "for idx, df in enumerate(df_array):\n",
    "    n = len(df)\n",
    "    train_df = df[0:int(n*0.7)]\n",
    "    val_df = df[int(n*0.7):int(n*0.9)]\n",
    "    test_df = df[int(n*0.9):]\n",
    "\n",
    "    # Min max sclaing\n",
    "    train_df = dh.min_max_scaling(train_df)\n",
    "    val_df = dh.min_max_scaling(val_df)\n",
    "    test_df = dh.min_max_scaling(test_df)\n",
    "\n",
    "    # Sequencing\n",
    "    train_sequences = dh.create_sequences(train_df, sequence_length)\n",
    "    val_sequences = dh.create_sequences(val_df, sequence_length)\n",
    "    test_sequences = dh.create_sequences(test_df, sequence_length)\n",
    "\n",
    "    #Split into feature and label\n",
    "    X_train[f'user{idx+1}'], y_train[f'user{idx+1}'] = dh.prepare_data(train_sequences, batch_size)\n",
    "    X_val[f'user{idx+1}'], y_val[f'user{idx+1}'] = dh.prepare_data(val_sequences, batch_size)\n",
    "    X_test[f'user{idx+1}'], y_test[f'user{idx+1}'] = dh.prepare_data(test_sequences, batch_size)\n",
    "\n",
    "#General Hyperparameters\n",
    "# #All models\n",
    "horizon = 1\n",
    "max_epochs = 100\n",
    "m1 = ModelGenerator()\n",
    "mh = Modelhandler()\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metrics=[\n",
    "    tf.keras.metrics.RootMeanSquaredError(), \n",
    "    tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "    tf.keras.metrics.MeanAbsoluteError(),\n",
    "]\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10,mode='min')\n",
    "timing_callback = TimingCallback()\n",
    "custom_callback = CustomCallback()\n",
    "#model_checkpoint = ModelCheckpoint('models/best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "callbacks=[early_stopping, timing_callback, custom_callback] #model_checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_weights(weight_list):\n",
    "    \"\"\"\n",
    "    Return the sum of the listed weights. The is equivalent to avg of the weights\n",
    "    \"\"\"\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*weight_list):\n",
    "        layer_mean = tf.math.reduce_mean(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning benchmark Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_results = pd.DataFrame(columns=['architecture', 'train_time', 'avg_time_epoch', 'mse','mse_std', 'rmse','rmse_std','mape','mape_std','mae','mae_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.loadtxt('evaluations/federated_learning/clusters.csv', delimiter=',').astype(int)\n",
    "num_clusters = 6\n",
    "cluster_users = {i: [] for i in range(num_clusters)}\n",
    "\n",
    "# Iterate through each cluster\n",
    "for cluster_number in range(num_clusters):\n",
    "    users_in_cluster = np.where(y == cluster_number)[0] +1\n",
    "    cluster_users[cluster_number] = users_in_cluster\n",
    "\n",
    "#Clustering logic: \n",
    "# Iterate through each cluster and its associated users\n",
    "\"\"\"for cluster_number, users_in_cluster in cluster_users.items():\n",
    "    print(f\"Cluster {cluster_number}:\")\n",
    "    \n",
    "    # Filter and print the users in the current cluster\n",
    "    for user_index in users_in_cluster:\n",
    "        user_df = df_array[user_index-1]  # Get the user's DataFrame from the array\n",
    "        print(f\"User {user_index}:\\n{user_df}\")\n",
    "    \n",
    "    print(\"\\n\") \n",
    "\n",
    "user_df\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense MODEL 1 ------------------------------------------------------------------\n",
    "dense_architecture = \"Dense_L3_U16\"\n",
    "dense_layers = 3\n",
    "dense_units = 16\n",
    "\n",
    "# Create global models for each cluser (6)\n",
    "for cluster in range(6):\n",
    "#Build and save global model\n",
    "    global_dense_moe = m1.build_dense_model(X_train[f'user{1}'], horizon, num_layers=dense_layers, units=dense_units, batch_size=batch_size)\n",
    "    global_dense_moe.save(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster}/{dense_architecture}/FederatedRound{0}\")\n",
    "\n",
    "  \n",
    "federated_rounds = 5\n",
    "for federated_round  in range(federated_rounds):\n",
    "    print(\"Started Federated training round ----------\", federated_round+1, f\"/ {federated_rounds}\")\n",
    "\n",
    "    for cluster_number, users_in_cluster in cluster_users.items():\n",
    "        print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "        #Get global models weights\n",
    "        global_dense_moe = keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_round}\", compile=False)\n",
    "        global_dense_moe_weights = global_dense_moe.get_weights()\n",
    "\n",
    "        #initial list for local model weights\n",
    "        local_dense_moe_weight_list = list()\n",
    "\n",
    "\n",
    "        #for idx, user in enumerate(df_array): \n",
    "        for user_index in users_in_cluster:\n",
    "            user_df = df_array[user_index-1]  # Get the user's DataFrame from the array\n",
    "            print(f\"User {user_index}\") \n",
    "                      \n",
    "            #build and compile local model X_train, batch_size, horizon, dense_units,  expert_units, num_experts, m1\n",
    "            local_dense_moe_model = m1.build_dense_model(X_train[f'user{user_index}'], horizon, num_layers=dense_layers, units=dense_units, batch_size=batch_size)\n",
    "            local_dense_moe_model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=metrics)\n",
    "\n",
    "            #set local model weight to the weight of the global model\n",
    "            local_dense_moe_model.set_weights(global_dense_moe_weights)\n",
    "            \n",
    "            #Fit local model to local data\n",
    "            dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "                model=local_dense_moe_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = max_epochs, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=dense_architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            )\n",
    "            #add model weights to list        \n",
    "            local_dense_moe_weights = local_dense_moe_model.get_weights()\n",
    "            local_dense_moe_weight_list.append(local_dense_moe_weights)\n",
    "        \n",
    "            #clear session to free memory after each communication round\n",
    "            K.clear_session()\n",
    "        \n",
    "        #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "        average_weights_dense_moe = sum_weights(local_dense_moe_weight_list)\n",
    "        #update global model \n",
    "        global_dense_moe.set_weights(average_weights_dense_moe)\n",
    "        #Save global models\n",
    "        global_dense_moe.save(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_round+1}\")\n",
    "        print(\"Saved Global models\")\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "dense_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "\n",
    "for cluster_number, users_in_cluster in cluster_users.items():\n",
    "    print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "    #Get global models weights\n",
    "    global_dense_moe = tf.keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "\n",
    "    #for idx, user in enumerate(df_array): \n",
    "    for user_index in users_in_cluster:\n",
    "        print(\"User: \", user_index)\n",
    "        for round in range(3):\n",
    "            global_dense_moe = tf.keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "            dense_moe_model = m1.build_dense_model(X_train[f'user{user_index}'], horizon, num_layers=dense_layers, units=dense_units, batch_size=batch_size)\n",
    "            dense_moe_model.set_weights(global_dense_moe.get_weights())\n",
    "            \n",
    "            dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "                model=dense_moe_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = max_epochs, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=dense_architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            )\n",
    "            # Add the 'architecture' column from dense_user_results to dense_results\n",
    "            dense_all_results = pd.merge(dense_all_results, dense_user_results, how='outer')  \n",
    "\n",
    "for idx in range(len(df_array)):\n",
    "    new_row = {\n",
    "        'architecture': dense_architecture,\n",
    "        'train_time': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"train_time\"].mean(), \n",
    "        'avg_time_epoch' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"avg_time_epoch\"].mean(),\n",
    "        'mse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].mean(),\n",
    "        'mse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].std(),\n",
    "        'rmse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].mean(),\n",
    "        'rmse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].std(),\n",
    "        'mape': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].mean(),\n",
    "        'mape_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].std(),\n",
    "        'mae': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].mean(),\n",
    "        'mae_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].std(),\n",
    "    }\n",
    "    dense_results.loc[len(dense_results)] = new_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_results.to_csv(f'evaluations/clustered_federated_learning/{dense_architecture}.csv')\n",
    "dense_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense MODEL 2 ------------------------------------------------------------------\n",
    "dense_architecture = \"Dense_L1_U4\"\n",
    "dense_layers = 1\n",
    "dense_units = 4\n",
    "\n",
    "# Create global models for each cluser (6)\n",
    "for cluster in range(6):\n",
    "#Build and save global model\n",
    "    global_dense_moe = m1.build_dense_model(X_train[f'user{1}'], horizon, num_layers=dense_layers, units=dense_units, batch_size=batch_size)\n",
    "    global_dense_moe.save(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster}/{dense_architecture}/FederatedRound{0}\")\n",
    "\n",
    "  \n",
    "federated_rounds = 5\n",
    "for federated_round  in range(federated_rounds):\n",
    "    print(\"Started Federated training round ----------\", federated_round+1, f\"/ {federated_rounds}\")\n",
    "\n",
    "    for cluster_number, users_in_cluster in cluster_users.items():\n",
    "        print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "        #Get global models weights\n",
    "        global_dense_moe = keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_round}\", compile=False)\n",
    "        global_dense_moe_weights = global_dense_moe.get_weights()\n",
    "\n",
    "        #initial list for local model weights\n",
    "        local_dense_moe_weight_list = list()\n",
    "\n",
    "\n",
    "        #for idx, user in enumerate(df_array): \n",
    "        for user_index in users_in_cluster:\n",
    "            user_df = df_array[user_index-1]  # Get the user's DataFrame from the array\n",
    "            print(f\"User {user_index}\") \n",
    "                      \n",
    "            #build and compile local model X_train, batch_size, horizon, dense_units,  expert_units, num_experts, m1\n",
    "            local_dense_moe_model = m1.build_dense_model(X_train[f'user{user_index}'], horizon, num_layers=dense_layers, units=dense_units, batch_size=batch_size)\n",
    "            local_dense_moe_model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=metrics)\n",
    "\n",
    "            #set local model weight to the weight of the global model\n",
    "            local_dense_moe_model.set_weights(global_dense_moe_weights)\n",
    "            \n",
    "            #Fit local model to local data\n",
    "            dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "                model=local_dense_moe_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = max_epochs, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=dense_architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            )\n",
    "            #add model weights to list        \n",
    "            local_dense_moe_weights = local_dense_moe_model.get_weights()\n",
    "            local_dense_moe_weight_list.append(local_dense_moe_weights)\n",
    "        \n",
    "            #clear session to free memory after each communication round\n",
    "            K.clear_session()\n",
    "        \n",
    "        #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "        average_weights_dense_moe = sum_weights(local_dense_moe_weight_list)\n",
    "        #update global model \n",
    "        global_dense_moe.set_weights(average_weights_dense_moe)\n",
    "        #Save global models\n",
    "        global_dense_moe.save(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_round+1}\")\n",
    "        print(\"Saved Global models\")\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "dense_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "\n",
    "for cluster_number, users_in_cluster in cluster_users.items():\n",
    "    print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "    #Get global models weights\n",
    "    global_dense_moe = tf.keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "\n",
    "    #for idx, user in enumerate(df_array): \n",
    "    for user_index in users_in_cluster:\n",
    "        print(\"User: \", user_index)\n",
    "        for round in range(3):\n",
    "            global_dense_moe = tf.keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "            dense_moe_model = m1.build_dense_model(X_train[f'user{user_index}'], horizon, num_layers=dense_layers, units=dense_units, batch_size=batch_size)\n",
    "            dense_moe_model.set_weights(global_dense_moe.get_weights())\n",
    "            \n",
    "            dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "                model=dense_moe_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = max_epochs, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=dense_architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            )\n",
    "            # Add the 'architecture' column from dense_user_results to dense_results\n",
    "            dense_all_results = pd.merge(dense_all_results, dense_user_results, how='outer')  \n",
    "\n",
    "for idx in range(len(df_array)):\n",
    "    new_row = {\n",
    "        'architecture': dense_architecture,\n",
    "        'train_time': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"train_time\"].mean(), \n",
    "        'avg_time_epoch' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"avg_time_epoch\"].mean(),\n",
    "        'mse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].mean(),\n",
    "        'mse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].std(),\n",
    "        'rmse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].mean(),\n",
    "        'rmse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].std(),\n",
    "        'mape': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].mean(),\n",
    "        'mape_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].std(),\n",
    "        'mae': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].mean(),\n",
    "        'mae_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].std(),\n",
    "    }\n",
    "    dense_results.loc[len(dense_results)] = new_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_results.to_csv(f'evaluations/clustered_federated_learning/{dense_architecture}.csv')\n",
    "dense_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense MODEL 3 ------------------------------------------------------------------\n",
    "dense_architecture = \"Dense_L5_U32\"\n",
    "dense_layers = 5\n",
    "dense_units = 32\n",
    "\n",
    "# Create global models for each cluser (6)\n",
    "for cluster in range(6):\n",
    "#Build and save global model\n",
    "    global_dense_moe = m1.build_dense_model(X_train[f'user{1}'], horizon, num_layers=dense_layers, units=dense_units, batch_size=batch_size)\n",
    "    global_dense_moe.save(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster}/{dense_architecture}/FederatedRound{0}\")\n",
    "\n",
    "  \n",
    "federated_rounds = 5\n",
    "for federated_round  in range(federated_rounds):\n",
    "    print(\"Started Federated training round ----------\", federated_round+1, f\"/ {federated_rounds}\")\n",
    "\n",
    "    for cluster_number, users_in_cluster in cluster_users.items():\n",
    "        print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "        #Get global models weights\n",
    "        global_dense_moe = keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_round}\", compile=False)\n",
    "        global_dense_moe_weights = global_dense_moe.get_weights()\n",
    "\n",
    "        #initial list for local model weights\n",
    "        local_dense_moe_weight_list = list()\n",
    "\n",
    "\n",
    "        #for idx, user in enumerate(df_array): \n",
    "        for user_index in users_in_cluster:\n",
    "            user_df = df_array[user_index-1]  # Get the user's DataFrame from the array\n",
    "            print(f\"User {user_index}\") \n",
    "                      \n",
    "            #build and compile local model X_train, batch_size, horizon, dense_units,  expert_units, num_experts, m1\n",
    "            local_dense_moe_model = m1.build_dense_model(X_train[f'user{user_index}'], horizon, num_layers=dense_layers, units=dense_units, batch_size=batch_size)\n",
    "            local_dense_moe_model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=metrics)\n",
    "\n",
    "            #set local model weight to the weight of the global model\n",
    "            local_dense_moe_model.set_weights(global_dense_moe_weights)\n",
    "            \n",
    "            #Fit local model to local data\n",
    "            dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "                model=local_dense_moe_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = max_epochs, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=dense_architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            )\n",
    "            #add model weights to list        \n",
    "            local_dense_moe_weights = local_dense_moe_model.get_weights()\n",
    "            local_dense_moe_weight_list.append(local_dense_moe_weights)\n",
    "        \n",
    "            #clear session to free memory after each communication round\n",
    "            K.clear_session()\n",
    "        \n",
    "        #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "        average_weights_dense_moe = sum_weights(local_dense_moe_weight_list)\n",
    "        #update global model \n",
    "        global_dense_moe.set_weights(average_weights_dense_moe)\n",
    "        #Save global models\n",
    "        global_dense_moe.save(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_round+1}\")\n",
    "        print(\"Saved Global models\")\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "dense_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "\n",
    "for cluster_number, users_in_cluster in cluster_users.items():\n",
    "    print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "    #Get global models weights\n",
    "    global_dense_moe = tf.keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "\n",
    "    #for idx, user in enumerate(df_array): \n",
    "    for user_index in users_in_cluster:\n",
    "        print(\"User: \", user_index)\n",
    "        for round in range(3):\n",
    "            global_dense_moe = tf.keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "            dense_moe_model = m1.build_dense_model(X_train[f'user{user_index}'], horizon, num_layers=dense_layers, units=dense_units, batch_size=batch_size)\n",
    "            dense_moe_model.set_weights(global_dense_moe.get_weights())\n",
    "            \n",
    "            dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "                model=dense_moe_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = max_epochs, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=dense_architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            )\n",
    "            # Add the 'architecture' column from dense_user_results to dense_results\n",
    "            dense_all_results = pd.merge(dense_all_results, dense_user_results, how='outer')  \n",
    "\n",
    "for idx in range(len(df_array)):\n",
    "    new_row = {\n",
    "        'architecture': dense_architecture,\n",
    "        'train_time': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"train_time\"].mean(), \n",
    "        'avg_time_epoch' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"avg_time_epoch\"].mean(),\n",
    "        'mse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].mean(),\n",
    "        'mse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].std(),\n",
    "        'rmse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].mean(),\n",
    "        'rmse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].std(),\n",
    "        'mape': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].mean(),\n",
    "        'mape_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].std(),\n",
    "        'mae': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].mean(),\n",
    "        'mae_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].std(),\n",
    "    }\n",
    "    dense_results.loc[len(dense_results)] = new_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_results.to_csv(f'evaluations/clustered_federated_learning/{dense_architecture}.csv')\n",
    "dense_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense MODEL 3 ------------------------------------------------------------------\n",
    "lstm_architecture = \"L2_U8\"\n",
    "lstm_layers = 2\n",
    "lstm_units = 8\n",
    "\n",
    "# Create global models for each cluser (6)\n",
    "for cluster in range(6):\n",
    "#Build and save global model\n",
    "    global_dense_moe = m1.build_bilstm_model(X_train[f'user{1}'], horizon, num_layers=lstm_layers, units=lstm_units, batch_size=batch_size)\n",
    "    global_dense_moe.save(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster}/{lstm_architecture}/FederatedRound{0}\")\n",
    "\n",
    "  \n",
    "federated_rounds = 5\n",
    "for federated_round  in range(federated_rounds):\n",
    "    print(\"Started Federated training round ----------\", federated_round+1, f\"/ {federated_rounds}\")\n",
    "\n",
    "    for cluster_number, users_in_cluster in cluster_users.items():\n",
    "        print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "        #Get global models weights\n",
    "        global_dense_moe = keras.models.load_model(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster_number}/{lstm_architecture}/FederatedRound{federated_round}\", compile=False)\n",
    "        global_dense_moe_weights = global_dense_moe.get_weights()\n",
    "\n",
    "        #initial list for local model weights\n",
    "        local_dense_moe_weight_list = list()\n",
    "\n",
    "\n",
    "        #for idx, user in enumerate(df_array): \n",
    "        for user_index in users_in_cluster:\n",
    "            user_df = df_array[user_index-1]  # Get the user's DataFrame from the array\n",
    "            print(f\"User {user_index}\") \n",
    "                      \n",
    "            #build and compile local model X_train, batch_size, horizon, dense_units,  expert_units, num_experts, m1\n",
    "            local_dense_moe_model = m1.build_bilstm_model(X_train[f'user{user_index}'], horizon, num_layers=lstm_layers, units=lstm_units, batch_size=batch_size)\n",
    "            local_dense_moe_model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=metrics)\n",
    "\n",
    "            #set local model weight to the weight of the global model\n",
    "            local_dense_moe_model.set_weights(global_dense_moe_weights)\n",
    "            \n",
    "            #Fit local model to local data\n",
    "            dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "                model=local_dense_moe_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = max_epochs, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=lstm_architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            )\n",
    "            #add model weights to list        \n",
    "            local_dense_moe_weights = local_dense_moe_model.get_weights()\n",
    "            local_dense_moe_weight_list.append(local_dense_moe_weights)\n",
    "        \n",
    "            #clear session to free memory after each communication round\n",
    "            K.clear_session()\n",
    "        \n",
    "        #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "        average_weights_dense_moe = sum_weights(local_dense_moe_weight_list)\n",
    "        #update global model \n",
    "        global_dense_moe.set_weights(average_weights_dense_moe)\n",
    "        #Save global models\n",
    "        global_dense_moe.save(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster_number}/{lstm_architecture}/FederatedRound{federated_round+1}\")\n",
    "        print(\"Saved Global models\")\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "dense_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "\n",
    "for cluster_number, users_in_cluster in cluster_users.items():\n",
    "    print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "    #Get global models weights\n",
    "    global_dense_moe = tf.keras.models.load_model(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster_number}/{lstm_architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "\n",
    "    #for idx, user in enumerate(df_array): \n",
    "    for user_index in users_in_cluster:\n",
    "        print(\"User: \", user_index)\n",
    "        for round in range(3):\n",
    "            global_dense_moe = tf.keras.models.load_model(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "            dense_moe_model = m1.build_bilstm_model(X_train[f'user{user_index}'], horizon, num_layers=lstm_layers, units=lstm_units, batch_size=batch_size)\n",
    "            dense_moe_model.set_weights(global_dense_moe.get_weights())\n",
    "            \n",
    "            dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "                model=dense_moe_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = max_epochs, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=lstm_architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            )\n",
    "            # Add the 'architecture' column from dense_user_results to dense_results\n",
    "            dense_all_results = pd.merge(dense_all_results, dense_user_results, how='outer')  \n",
    "\n",
    "for idx in range(len(df_array)):\n",
    "    new_row = {\n",
    "        'architecture': lstm_architecture,\n",
    "        'train_time': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"train_time\"].mean(), \n",
    "        'avg_time_epoch' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"avg_time_epoch\"].mean(),\n",
    "        'mse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].mean(),\n",
    "        'mse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].std(),\n",
    "        'rmse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].mean(),\n",
    "        'rmse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].std(),\n",
    "        'mape': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].mean(),\n",
    "        'mape_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].std(),\n",
    "        'mae': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].mean(),\n",
    "        'mae_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].std(),\n",
    "    }\n",
    "    dense_results.loc[len(dense_results)] = new_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_results.to_csv(f'evaluations/clustered_federated_learning/{lstm_architecture}.csv')\n",
    "dense_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense MODEL 2 ------------------------------------------------------------------\n",
    "lstm_architecture = \"L1_U8\"\n",
    "lstm_layers = 1\n",
    "lstm_units = 8\n",
    "\n",
    "# Create global models for each cluser (6)\n",
    "for cluster in range(6):\n",
    "#Build and save global model\n",
    "    global_dense_moe = m1.build_bilstm_model(X_train[f'user{1}'], horizon, num_layers=lstm_layers, units=lstm_units, batch_size=batch_size)\n",
    "    global_dense_moe.save(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster}/{lstm_architecture}/FederatedRound{0}\")\n",
    "\n",
    "  \n",
    "federated_rounds = 5\n",
    "for federated_round  in range(federated_rounds):\n",
    "    print(\"Started Federated training round ----------\", federated_round+1, f\"/ {federated_rounds}\")\n",
    "\n",
    "    for cluster_number, users_in_cluster in cluster_users.items():\n",
    "        print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "        #Get global models weights\n",
    "        global_dense_moe = keras.models.load_model(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster_number}/{lstm_architecture}/FederatedRound{federated_round}\", compile=False)\n",
    "        global_dense_moe_weights = global_dense_moe.get_weights()\n",
    "\n",
    "        #initial list for local model weights\n",
    "        local_dense_moe_weight_list = list()\n",
    "\n",
    "\n",
    "        #for idx, user in enumerate(df_array): \n",
    "        for user_index in users_in_cluster:\n",
    "            user_df = df_array[user_index-1]  # Get the user's DataFrame from the array\n",
    "            print(f\"User {user_index}\") \n",
    "                      \n",
    "            #build and compile local model X_train, batch_size, horizon, dense_units,  expert_units, num_experts, m1\n",
    "            local_dense_moe_model = m1.build_bilstm_model(X_train[f'user{user_index}'], horizon, num_layers=lstm_layers, units=lstm_units, batch_size=batch_size)\n",
    "            local_dense_moe_model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=metrics)\n",
    "\n",
    "            #set local model weight to the weight of the global model\n",
    "            local_dense_moe_model.set_weights(global_dense_moe_weights)\n",
    "            \n",
    "            #Fit local model to local data\n",
    "            dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "                model=local_dense_moe_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = max_epochs, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=lstm_architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            )\n",
    "            #add model weights to list        \n",
    "            local_dense_moe_weights = local_dense_moe_model.get_weights()\n",
    "            local_dense_moe_weight_list.append(local_dense_moe_weights)\n",
    "        \n",
    "            #clear session to free memory after each communication round\n",
    "            K.clear_session()\n",
    "        \n",
    "        #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "        average_weights_dense_moe = sum_weights(local_dense_moe_weight_list)\n",
    "        #update global model \n",
    "        global_dense_moe.set_weights(average_weights_dense_moe)\n",
    "        #Save global models\n",
    "        global_dense_moe.save(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster_number}/{lstm_architecture}/FederatedRound{federated_round+1}\")\n",
    "        print(\"Saved Global models\")\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "dense_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "\n",
    "for cluster_number, users_in_cluster in cluster_users.items():\n",
    "    print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "    #Get global models weights\n",
    "    global_dense_moe = tf.keras.models.load_model(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster_number}/{lstm_architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "\n",
    "    #for idx, user in enumerate(df_array): \n",
    "    for user_index in users_in_cluster:\n",
    "        print(\"User: \", user_index)\n",
    "        for round in range(3):\n",
    "            global_dense_moe = tf.keras.models.load_model(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "            dense_moe_model = m1.build_bilstm_model(X_train[f'user{user_index}'], horizon, num_layers=lstm_layers, units=lstm_units, batch_size=batch_size)\n",
    "            dense_moe_model.set_weights(global_dense_moe.get_weights())\n",
    "            \n",
    "            dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "                model=dense_moe_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = max_epochs, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=lstm_architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            )\n",
    "            # Add the 'architecture' column from dense_user_results to dense_results\n",
    "            dense_all_results = pd.merge(dense_all_results, dense_user_results, how='outer')  \n",
    "\n",
    "for idx in range(len(df_array)):\n",
    "    new_row = {\n",
    "        'architecture': lstm_architecture,\n",
    "        'train_time': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"train_time\"].mean(), \n",
    "        'avg_time_epoch' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"avg_time_epoch\"].mean(),\n",
    "        'mse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].mean(),\n",
    "        'mse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].std(),\n",
    "        'rmse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].mean(),\n",
    "        'rmse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].std(),\n",
    "        'mape': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].mean(),\n",
    "        'mape_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].std(),\n",
    "        'mae': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].mean(),\n",
    "        'mae_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].std(),\n",
    "    }\n",
    "    dense_results.loc[len(dense_results)] = new_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_results.to_csv(f'evaluations/clustered_federated_learning/{dense_architecture}.csv')\n",
    "dense_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense MODEL 3 ------------------------------------------------------------------\n",
    "lstm_architecture = \"L2_U20\"\n",
    "lstm_layers = 2\n",
    "lstm_units = 20\n",
    "\n",
    "# Create global models for each cluser (6)\n",
    "for cluster in range(6):\n",
    "#Build and save global model\n",
    "    global_dense_moe = m1.build_bilstm_model(X_train[f'user{1}'], horizon, num_layers=lstm_layers, units=lstm_units, batch_size=batch_size)\n",
    "    global_dense_moe.save(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster}/{lstm_architecture}/FederatedRound{0}\")\n",
    "\n",
    "  \n",
    "federated_rounds = 5\n",
    "for federated_round  in range(federated_rounds):\n",
    "    print(\"Started Federated training round ----------\", federated_round+1, f\"/ {federated_rounds}\")\n",
    "\n",
    "    for cluster_number, users_in_cluster in cluster_users.items():\n",
    "        print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "        #Get global models weights\n",
    "        global_dense_moe = keras.models.load_model(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster_number}/{lstm_architecture}/FederatedRound{federated_round}\", compile=False)\n",
    "        global_dense_moe_weights = global_dense_moe.get_weights()\n",
    "\n",
    "        #initial list for local model weights\n",
    "        local_dense_moe_weight_list = list()\n",
    "\n",
    "\n",
    "        #for idx, user in enumerate(df_array): \n",
    "        for user_index in users_in_cluster:\n",
    "            user_df = df_array[user_index-1]  # Get the user's DataFrame from the array\n",
    "            print(f\"User {user_index}\") \n",
    "                      \n",
    "            #build and compile local model X_train, batch_size, horizon, dense_units,  expert_units, num_experts, m1\n",
    "            local_dense_moe_model = m1.build_bilstm_model(X_train[f'user{user_index}'], horizon, num_layers=lstm_layers, units=lstm_units, batch_size=batch_size)\n",
    "            local_dense_moe_model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=metrics)\n",
    "\n",
    "            #set local model weight to the weight of the global model\n",
    "            local_dense_moe_model.set_weights(global_dense_moe_weights)\n",
    "            \n",
    "            #Fit local model to local data\n",
    "            dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "                model=local_dense_moe_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = max_epochs, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=lstm_architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            )\n",
    "            #add model weights to list        \n",
    "            local_dense_moe_weights = local_dense_moe_model.get_weights()\n",
    "            local_dense_moe_weight_list.append(local_dense_moe_weights)\n",
    "        \n",
    "            #clear session to free memory after each communication round\n",
    "            K.clear_session()\n",
    "        \n",
    "        #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "        average_weights_dense_moe = sum_weights(local_dense_moe_weight_list)\n",
    "        #update global model \n",
    "        global_dense_moe.set_weights(average_weights_dense_moe)\n",
    "        #Save global models\n",
    "        global_dense_moe.save(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster_number}/{lstm_architecture}/FederatedRound{federated_round+1}\")\n",
    "        print(\"Saved Global models\")\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "dense_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "\n",
    "for cluster_number, users_in_cluster in cluster_users.items():\n",
    "    print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "    #Get global models weights\n",
    "    global_dense_moe = tf.keras.models.load_model(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster_number}/{lstm_architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "\n",
    "    #for idx, user in enumerate(df_array): \n",
    "    for user_index in users_in_cluster:\n",
    "        print(\"User: \", user_index)\n",
    "        for round in range(3):\n",
    "            global_dense_moe = tf.keras.models.load_model(cwd + f\"/models/FL/LSTM/global_lstm_model/cluster_{cluster_number}/{dense_architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "            dense_moe_model = m1.build_bilstm_model(X_train[f'user{user_index}'], horizon, num_layers=lstm_layers, units=lstm_units, batch_size=batch_size)\n",
    "            dense_moe_model.set_weights(global_dense_moe.get_weights())\n",
    "            \n",
    "            dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "                model=dense_moe_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = max_epochs, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=lstm_architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            )\n",
    "            # Add the 'architecture' column from dense_user_results to dense_results\n",
    "            dense_all_results = pd.merge(dense_all_results, dense_user_results, how='outer')  \n",
    "\n",
    "for idx in range(len(df_array)):\n",
    "    new_row = {\n",
    "        'architecture': lstm_architecture,\n",
    "        'train_time': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"train_time\"].mean(), \n",
    "        'avg_time_epoch' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"avg_time_epoch\"].mean(),\n",
    "        'mse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].mean(),\n",
    "        'mse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].std(),\n",
    "        'rmse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].mean(),\n",
    "        'rmse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].std(),\n",
    "        'mape': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].mean(),\n",
    "        'mape_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].std(),\n",
    "        'mae': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].mean(),\n",
    "        'mae_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].std(),\n",
    "    }\n",
    "    dense_results.loc[len(dense_results)] = new_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_results.to_csv(f'evaluations/clustered_federated_learning/{dense_architecture}.csv')\n",
    "dense_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
