{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.modelgenerator import *\n",
    "from utils.modelhandler import *\n",
    "from utils.datahandler import *\n",
    "\n",
    "#Get data \n",
    "cwd = os.path.normpath(os.getcwd())\n",
    "df = pd.read_csv(cwd+'/data/df_with_final_features.csv', index_col='Date') #df = pd.read_csv('user5.csv')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "#df = df[['User5', 'temp', 'rhum']]\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df_array = []\n",
    "for idx in range(2):\n",
    "    df_array.append(df[[f'User{idx+1}', 'temp', 'rhum', 'wspd', 'PC1', 'hour sin', 'hour cos', f'User{idx+1}_lag_24hrs']])\n",
    "\n",
    "#df_array[3].head(3)\n",
    "\n",
    "#Train, Validation and Test datasets\n",
    "sequence_length = 25\n",
    "batch_size = 16\n",
    "num_features = df_array[0].shape[1]\n",
    "\n",
    "dh = Datahandler()\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "#Create Train, Validation and Test datasets\n",
    "for idx, df in enumerate(df_array):\n",
    "    n = len(df)\n",
    "    train_df = df[0:int(n*0.7)]\n",
    "    val_df = df[int(n*0.7):int(n*0.9)]\n",
    "    test_df = df[int(n*0.9):]\n",
    "\n",
    "    # Min max sclaing\n",
    "    train_df = dh.min_max_scaling(train_df)\n",
    "    val_df = dh.min_max_scaling(val_df)\n",
    "    test_df = dh.min_max_scaling(test_df)\n",
    "\n",
    "    # Sequencing\n",
    "    train_sequences = dh.create_sequences(train_df, sequence_length)\n",
    "    val_sequences = dh.create_sequences(val_df, sequence_length)\n",
    "    test_sequences = dh.create_sequences(test_df, sequence_length)\n",
    "\n",
    "    #Split into feature and label\n",
    "    X_train[f'user{idx+1}'], y_train[f'user{idx+1}'] = dh.prepare_data(train_sequences, batch_size)\n",
    "    X_val[f'user{idx+1}'], y_val[f'user{idx+1}'] = dh.prepare_data(val_sequences, batch_size)\n",
    "    X_test[f'user{idx+1}'], y_test[f'user{idx+1}'] = dh.prepare_data(test_sequences, batch_size)\n",
    "\n",
    "#General Hyperparameters\n",
    "# #All models\n",
    "horizon = 1\n",
    "max_epochs = 100\n",
    "m1 = ModelGenerator()\n",
    "mh = Modelhandler()\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metrics=[\n",
    "    tf.keras.metrics.RootMeanSquaredError(), \n",
    "    tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "    tf.keras.metrics.MeanAbsoluteError(),\n",
    "]\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10,mode='min')\n",
    "timing_callback = TimingCallback()\n",
    "custom_callback = CustomCallback()\n",
    "#model_checkpoint = ModelCheckpoint('models/best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "callbacks=[early_stopping, timing_callback, custom_callback] #model_checkpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_results = pd.DataFrame(columns=['architecture', 'train_time', 'avg_time_epoch', 'mse','mse_std', 'rmse','rmse_std','mape','mape_std','mae','mae_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dense_model(X_train, horizon, num_layers, units, batch_size):\n",
    "\n",
    "    input_data = layers.Input(shape=(X_train.shape[1], X_train.shape[2]), batch_size=batch_size) \n",
    "    x =  layers.Dense(units, activation='relu')(input_data)\n",
    "    for _ in range(num_layers-1):\n",
    "      x = layers.Dense(units, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    output = layers.Dense(horizon)(x) \n",
    "\n",
    "    dense_model = tf.keras.Model(inputs=input_data, outputs=output, name=\"Dense_model\")\n",
    "\n",
    "    return dense_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  1\n",
      "User:  2\n"
     ]
    }
   ],
   "source": [
    "#Dense Model\n",
    "\n",
    "#Dense Hyperparameter\n",
    "dense_architecture = \"L3_U16\"\n",
    "dense_layers = 3\n",
    "dense_units = 16\n",
    "dense_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "\n",
    "#For each of the 3 user\n",
    "for idx in range(len(df_array)):\n",
    "    print(\"User: \", idx+1)\n",
    "    for round in range(3):\n",
    "        #print(\"Round: \", round)\n",
    "        dense_model = build_dense_model(X_train[f'user{idx+1}'], horizon, num_layers=dense_layers, units=dense_units, batch_size=batch_size)\n",
    "        dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "            model=dense_model, \n",
    "            loss=loss, \n",
    "            metrics=metrics, \n",
    "            X_train=X_train[f'user{idx+1}'],\n",
    "            y_train = y_train[f'user{idx+1}'], \n",
    "            max_epochs = max_epochs, \n",
    "            batch_size=batch_size, \n",
    "            X_val=X_val[f'user{idx+1}'], \n",
    "            y_val=y_val[f'user{idx+1}'], \n",
    "            X_test=X_test[f'user{idx+1}'], \n",
    "            y_test=y_test[f'user{idx+1}'], \n",
    "            callbacks=callbacks, \n",
    "            user=f'user{idx+1}', \n",
    "            hyper=dense_architecture,\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        )\n",
    "        # Add the 'architecture' column from dense_user_results to dense_results\n",
    "        dense_all_results = pd.merge(dense_all_results, dense_user_results, how='outer')   \n",
    "\n",
    "for idx in range(len(df_array)):\n",
    "    new_row = {\n",
    "        'architecture': dense_all_results[\"architecture\"][0],\n",
    "        'train_time': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"train_time\"].mean(), \n",
    "        'avg_time_epoch' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"avg_time_epoch\"].mean(),\n",
    "        'mse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].mean(),\n",
    "        'mse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].std(),\n",
    "        'rmse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].mean(),\n",
    "        'rmse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].std(),\n",
    "        'mape': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].mean(),\n",
    "        'mape_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].std(),\n",
    "        'mae': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].mean(),\n",
    "        'mae_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].std(),\n",
    "    }\n",
    "    dense_results.loc[len(dense_results)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean total train time:  8.16236412525177\n",
      "Mean train time epoch:  0.34206747128921855\n",
      "Mean mse:  0.02608363050967455\n",
      "Mean rmse:  0.15948817382256192\n",
      "Mean mape:  135305.29296875\n",
      "Mean mae:  0.10177501415212949\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean total train time: \", dense_results[\"train_time\"].mean())\n",
    "print(\"Mean train time epoch: \", dense_results[\"avg_time_epoch\"].mean())\n",
    "print(\"Mean mse: \", dense_results[\"mse\"].mean())\n",
    "print(\"Mean rmse: \", dense_results[\"rmse\"].mean())\n",
    "print(\"Mean mape: \", dense_results[\"mape\"].mean())\n",
    "print(\"Mean mae: \", dense_results[\"mae\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoE top k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_moe_results = pd.DataFrame(columns=['architecture', 'train_time', 'avg_time_epoch', 'mse','mse_std', 'rmse','rmse_std','mape','mape_std','mae','mae_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builds the expert models for the MoE Layer\n",
    "def build_expert_network(expert_units):\n",
    "    expert = keras.Sequential([\n",
    "            layers.Dense(expert_units, activation=\"relu\"), \n",
    "            ])\n",
    "    return expert\n",
    "\n",
    "\n",
    "#Builds a MoE model with top_k gating\n",
    "def build_topk_dense_moe_model(X_train, batch_size, horizon, dense_units, num_experts, top_k, expert_units, m1):\n",
    "    #Input of shape (batch_size, sequence_length, features)\n",
    "    inputs = layers.Input(shape=(X_train.shape[1], X_train.shape[2]), batch_size=batch_size, name='input_layer') \n",
    "    x = layers.Dense(dense_units, activation=\"relu\")(inputs)\n",
    "    \n",
    "\n",
    "    #EMBEDDED MOE LAYER\n",
    "    # ROUTER\n",
    "    router_inputs = inputs \n",
    "    print(\"router_inputs: \", router_inputs) #(16, 24, 8)\n",
    "    router_probs = layers.Dense(num_experts, activation='softmax')(router_inputs)\n",
    "    print(\"router_probs: \", router_probs) #(16, 24, 5)\n",
    "    expert_gate, expert_index = tf.math.top_k(router_probs, k=top_k)\n",
    "    print(\"expert_gate: \", expert_gate) #(16, 24, 2)\n",
    "    print(\"expert_index: \", expert_index) #(16, 24, 2)\n",
    "    expert_idx_mask = tf.one_hot(expert_index, depth=num_experts)\n",
    "    print(\"expert_idx_mask: \", expert_idx_mask) #(16, 24, 2, 5)\n",
    "    combined_tensor = tf.einsum('abc,abcd->abd', expert_gate, expert_idx_mask)\n",
    "    print(\"combined_tensor: \", combined_tensor) #(16, 24, 5)\n",
    "\n",
    "    #expert_inputs = tf.einsum(\"abc,abd->dabc\", router_inputs, combined_tensor) # Instead of (3,4) -> (3, 16, 24, 4)\n",
    "    #print(\"expert_inputs: \", expert_inputs) (5, 16, 24, 8)\n",
    "\n",
    "\n",
    "    #expert_input_list = tf.unstack(expert_inputs, axis=0)\n",
    "    #print(\"expert_input_list: \", expert_input_list) #[(16, 24, 8), (16, 24, 8), (16, 24, 8), (16, 24, 8), (16, 24, 8)]\n",
    "\n",
    "    expert_inputs = tf.einsum(\"abc,abd->dac\", router_inputs, combined_tensor) # Instead of (3,4) -> (3, 16, 24, 4)\n",
    "    print(\"expert_inputs: \", expert_inputs) #(5, 8)\n",
    "    \n",
    "    expert_input_list = tf.unstack(expert_inputs, axis=0)\n",
    "    print(\"expert_input_list: \", expert_input_list) #[(16, 8)]\n",
    "\n",
    "\n",
    "\n",
    "    expert_output_list = [\n",
    "            [build_expert_network(expert_units=expert_units) for _ in range(num_experts)][idx](expert_input)\n",
    "            for idx, expert_input in enumerate(expert_input_list)\n",
    "        ]\n",
    "    \n",
    "    expert_outputs = tf.stack(expert_output_list, axis=1)\n",
    "    expert_outputs_combined = tf.einsum(\n",
    "            \"abcd,ace->acd\", expert_outputs, combined_tensor #(16, 2, 24, 4) and (16, 24, 3)\n",
    "        )    \n",
    "    moe_output = expert_outputs_combined\n",
    "    #END MOE LAYER\n",
    "\n",
    "    #BOTTOM Model\n",
    "    x = layers.Dropout(0.2)(moe_output)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(horizon)(x)\n",
    "    topk_moe_model = models.Model(inputs=inputs, outputs=outputs, name=\"topk_moe\")\n",
    "\n",
    "    return topk_moe_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  1\n",
      "router_inputs:  KerasTensor(type_spec=TensorSpec(shape=(16, 24, 8), dtype=tf.float32, name='input_layer'), name='input_layer', description=\"created by layer 'input_layer'\")\n",
      "router_probs:  KerasTensor(type_spec=TensorSpec(shape=(16, 24, 5), dtype=tf.float32, name=None), name='dense_44/Softmax:0', description=\"created by layer 'dense_44'\")\n",
      "expert_gate:  KerasTensor(type_spec=TensorSpec(shape=(16, 24, 2), dtype=tf.float32, name=None), name='tf.math.top_k_4/TopKV2:0', description=\"created by layer 'tf.math.top_k_4'\")\n",
      "expert_index:  KerasTensor(type_spec=TensorSpec(shape=(16, 24, 2), dtype=tf.int32, name=None), name='tf.math.top_k_4/TopKV2:1', description=\"created by layer 'tf.math.top_k_4'\")\n",
      "expert_idx_mask:  KerasTensor(type_spec=TensorSpec(shape=(16, 24, 2, 5), dtype=tf.float32, name=None), name='tf.one_hot_4/one_hot:0', description=\"created by layer 'tf.one_hot_4'\")\n",
      "combined_tensor:  KerasTensor(type_spec=TensorSpec(shape=(16, 24, 5), dtype=tf.float32, name=None), name='tf.einsum_9/einsum/Einsum:0', description=\"created by layer 'tf.einsum_9'\")\n",
      "expert_inputs:  KerasTensor(type_spec=TensorSpec(shape=(5, 16, 8), dtype=tf.float32, name=None), name='tf.einsum_10/einsum/Einsum:0', description=\"created by layer 'tf.einsum_10'\")\n",
      "expert_input_list:  [<KerasTensor: shape=(16, 8) dtype=float32 (created by layer 'tf.unstack_3')>, <KerasTensor: shape=(16, 8) dtype=float32 (created by layer 'tf.unstack_3')>, <KerasTensor: shape=(16, 8) dtype=float32 (created by layer 'tf.unstack_3')>, <KerasTensor: shape=(16, 8) dtype=float32 (created by layer 'tf.unstack_3')>, <KerasTensor: shape=(16, 8) dtype=float32 (created by layer 'tf.unstack_3')>]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"tf.einsum_11\" (type TFOpLambda).\n\nShape must be rank 4 but is rank 3\n\t for 0th input and equation: abcd,ace->acd for '{{node tf.einsum_11/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"abcd,ace->acd\"](Placeholder, Placeholder_1)' with input shapes: [16,5,8], [16,24,5].\n\nCall arguments received by layer \"tf.einsum_11\" (type TFOpLambda):\n  • equation='abcd,ace->acd'\n  • inputs=('tf.Tensor(shape=(16, 5, 8), dtype=float32)', 'tf.Tensor(shape=(16, 24, 5), dtype=float32)')\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF\\14Comparing_Dense_and_moe.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mUser: \u001b[39m\u001b[39m\"\u001b[39m, idx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mround\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m#print(\"Round: \", round)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     dense_model \u001b[39m=\u001b[39m build_topk_dense_moe_model(X_train[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m{\u001b[39;49;00midx\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m], batch_size, horizon, dense_units, num_experts, top_k, expert_units, m1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     dense_histroy, dense_user_results \u001b[39m=\u001b[39m mh\u001b[39m.\u001b[39mcompile_fit_evaluate_model(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         model\u001b[39m=\u001b[39mdense_model, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         loss\u001b[39m=\u001b[39mloss, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m# Add the 'architecture' column from dense_user_results to dense_results\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF\\14Comparing_Dense_and_moe.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m expert_output_list \u001b[39m=\u001b[39m [\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m         [build_expert_network(expert_units\u001b[39m=\u001b[39mexpert_units) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_experts)][idx](expert_input)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m         \u001b[39mfor\u001b[39;00m idx, expert_input \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(expert_input_list)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m expert_outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mstack(expert_output_list, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m expert_outputs_combined \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49meinsum(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mabcd,ace->acd\u001b[39;49m\u001b[39m\"\u001b[39;49m, expert_outputs, combined_tensor \u001b[39m#(16, 2, 24, 4) and (16, 24, 3)\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     )    \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m moe_output \u001b[39m=\u001b[39m expert_outputs_combined\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m#END MOE LAYER\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rs1044/bwSyncShare/02Python%20Code/MoE-based-FL-for-secure-STLF/14Comparing_Dense_and_moe.ipynb#X12sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m#BOTTOM Model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\tf_op_layer.py:119\u001b[0m, in \u001b[0;36mKerasOpDispatcher.handle\u001b[1;34m(self, op, args, kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Handle the specified operation with the specified arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[0;32m    116\u001b[0m     \u001b[39misinstance\u001b[39m(x, keras_tensor\u001b[39m.\u001b[39mKerasTensor)\n\u001b[0;32m    117\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten([args, kwargs])\n\u001b[0;32m    118\u001b[0m ):\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m TFOpLambda(op)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    120\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mNOT_SUPPORTED\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"tf.einsum_11\" (type TFOpLambda).\n\nShape must be rank 4 but is rank 3\n\t for 0th input and equation: abcd,ace->acd for '{{node tf.einsum_11/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"abcd,ace->acd\"](Placeholder, Placeholder_1)' with input shapes: [16,5,8], [16,24,5].\n\nCall arguments received by layer \"tf.einsum_11\" (type TFOpLambda):\n  • equation='abcd,ace->acd'\n  • inputs=('tf.Tensor(shape=(16, 5, 8), dtype=float32)', 'tf.Tensor(shape=(16, 24, 5), dtype=float32)')\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "mh = Modelhandler()\n",
    "dense_moe_architecture = \"top2_exp5_d8\" #top2_exp5_d8\n",
    "dense_units = 16\n",
    "\n",
    "num_experts = 5\n",
    "expert_units = 8\n",
    "top_k = 1\n",
    "\n",
    "dense_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "#For each of the 3 user\n",
    "for idx in range(len(df_array)):\n",
    "    print(\"User: \", idx+1)\n",
    "    for round in range(1):\n",
    "        #print(\"Round: \", round)\n",
    "        dense_model = build_topk_dense_moe_model(X_train[f'user{idx+1}'], batch_size, horizon, dense_units, num_experts, top_k, expert_units, m1)\n",
    "        dense_histroy, dense_user_results = mh.compile_fit_evaluate_model(\n",
    "            model=dense_model, \n",
    "            loss=loss, \n",
    "            metrics=metrics, \n",
    "            X_train=X_train[f'user{idx+1}'],\n",
    "            y_train = y_train[f'user{idx+1}'], \n",
    "            max_epochs = max_epochs, \n",
    "            batch_size=batch_size, \n",
    "            X_val=X_val[f'user{idx+1}'], \n",
    "            y_val=y_val[f'user{idx+1}'], \n",
    "            X_test=X_test[f'user{idx+1}'], \n",
    "            y_test=y_test[f'user{idx+1}'], \n",
    "            callbacks=callbacks, \n",
    "            user=f'user{idx+1}', \n",
    "            hyper=dense_moe_architecture,\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        )\n",
    "        # Add the 'architecture' column from dense_user_results to dense_results\n",
    "        dense_all_results = pd.merge(dense_all_results, dense_user_results, how='outer')   \n",
    "        mh.plot_model_predictions(dense_model, dense_histroy, y_test[f'user{idx+1}'], X_test[f'user{idx+1}'], batch_size)\n",
    "\n",
    "for idx in range(len(df_array)):\n",
    "    new_row = {\n",
    "        'architecture': dense_all_results[\"architecture\"][0],\n",
    "        'train_time': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"train_time\"].mean(), \n",
    "        'avg_time_epoch' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"avg_time_epoch\"].mean(),\n",
    "        'mse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].mean(),\n",
    "        'mse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].std(),\n",
    "        'rmse': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].mean(),\n",
    "        'rmse_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].std(),\n",
    "        'mape': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].mean(),\n",
    "        'mape_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].std(),\n",
    "        'mae': dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].mean(),\n",
    "        'mae_std' : dense_all_results[dense_all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].std(),\n",
    "    }\n",
    "    dense_moe_results.loc[len(dense_moe_results)] = new_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Model -----------------------------------\n",
      "Mean total train time:  8.16236412525177\n",
      "Mean train time epoch:  0.34206747128921855\n",
      "Mean mse:  0.02608363050967455\n",
      "Mean rmse:  0.15948817382256192\n",
      "Mean mape:  135305.29296875\n",
      "Mean mae:  0.10177501415212949\n",
      "Mixture of Experts Dense Model -----------------------------------\n",
      "Mean total train time:  26.797215541203816\n",
      "Mean train time epoch:  0.6380768816364883\n",
      "Mean mse:  0.02796006730447213\n",
      "Mean rmse:  0.1648175356288751\n",
      "Mean mape:  150801.8330078125\n",
      "Mean mae:  0.1062221818914016\n"
     ]
    }
   ],
   "source": [
    "#Test 1: 1 expert (16), top 1\n",
    "print(\"Dense Model -----------------------------------\")\n",
    "print(\"Mean total train time: \", dense_results[\"train_time\"].mean())\n",
    "print(\"Mean train time epoch: \", dense_results[\"avg_time_epoch\"].mean())\n",
    "print(\"Mean mse: \", dense_results[\"mse\"].mean())\n",
    "print(\"Mean rmse: \", dense_results[\"rmse\"].mean())\n",
    "print(\"Mean mape: \", dense_results[\"mape\"].mean())\n",
    "print(\"Mean mae: \", dense_results[\"mae\"].mean())\n",
    "\n",
    "print(\"Mixture of Experts Dense Model -----------------------------------\")\n",
    "print(\"Mean total train time: \", dense_moe_results[\"train_time\"].mean())\n",
    "print(\"Mean train time epoch: \", dense_moe_results[\"avg_time_epoch\"].mean())\n",
    "print(\"Mean mse: \", dense_moe_results[\"mse\"].mean())\n",
    "print(\"Mean rmse: \", dense_moe_results[\"rmse\"].mean())\n",
    "print(\"Mean mape: \", dense_moe_results[\"mape\"].mean())\n",
    "print(\"Mean mae: \", dense_moe_results[\"mae\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[batch, group, experts, expert_capacity]\n",
    "combined_tensor\n",
    "\n",
    "  Dimensions cheat sheet:\n",
    "  a, b: batch size\n",
    "  l: original sequence length\n",
    "  m: input depth\n",
    "  n: output depth\n",
    "  g, h: number of groups\n",
    "  s, t: group size\n",
    "  x, y: number of experts\n",
    "  c, d: expert capacity\n",
    "\n",
    "   # Now create expert_inputs based on the assignments.\n",
    "  # put num_experts dimension first to make split easier in alltoall\n",
    "  expert_inputs_y = mtf.einsum([inputs_y, dispatch_tensor_y], [y, x1, h0, d, m])\n",
    "\n",
    "  # Second level, all to all. Here we change the split dimension from h0 to y0.\n",
    "  expert_inputs_y = mtf.reshape(expert_inputs_y, mtf.Shape(\n",
    "      [y0, x1, h, d, m]))\n",
    "\n",
    "  hidden_output = mtf.layers.dense(\n",
    "      expert_inputs_y, hidden_dim, expert_dims=[y0, x1],\n",
    "      activation=mtf.relu, use_bias=False, master_dtype=master_dtype,\n",
    "      slice_dtype=slice_dtype, name=\"expert0\")\n",
    "  expert_output = mtf.layers.dense(\n",
    "      hidden_output, output_dim, expert_dims=[y0, x1],\n",
    "      use_bias=False, master_dtype=master_dtype, slice_dtype=slice_dtype,\n",
    "      name=\"expert1\")\n",
    "\n",
    "  # NOW COMBINE EXPERT OUTPUTS (reversing everything we have done)\n",
    "  # expert_output has shape [y0, x1, h, d, n]\n",
    "\n",
    "  # alltoall\n",
    "  expert_output = mtf.reshape(expert_output, mtf.Shape(\n",
    "      [y, x1, h0, d, n]))\n",
    "\n",
    "  # combine results from inner level\n",
    "  output_y = mtf.einsum([expert_output, combine_tensor_y], [x1, h0, t, n])\n",
    "\n",
    "  # Reshape the combined tensor from inner level to now contain outer_batch_dim\n",
    "  # a0 and group_dim g\n",
    "  output = mtf.reshape(output_y, [x1, a0, g, c, n])\n",
    "\n",
    "  # alltoall from expert_dim x to group_dim g1\n",
    "  expert_output_x = mtf.reshape(output, mtf.Shape([x, a0, g1, c, n]))\n",
    "\n",
    "  # combine results from outer level\n",
    "  output_x = mtf.einsum([expert_output_x, combine_tensor_x], [a0, g1, s, n])\n",
    "\n",
    "  # Reshape the combined tensor to now contain inner_batch_dim\n",
    "  # b1 and the original sequence length\n",
    "  output = mtf.reshape(output_x, [a0, b1, l, n])\n",
    "  if insert_outer_batch_dim:\n",
    "    output = mtf.reshape(output, [b1, l, n])\n",
    "  return output, (loss_outer + loss_inner) * hparams.moe_loss_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _top_2_gating(\n",
    "    inputs, outer_expert_dims, experts_dim, expert_capacity_dim,\n",
    "    hparams, train, importance=None):\n",
    "  \n",
    "  # Inputs: [<batch_dims>, group_size_dim, input_dim]\n",
    "  # expert_dim: a Dimension (the number of experts)\n",
    "  # expert_capacity_dim: a Dimension (number of examples per group per expert)\n",
    "  # hparams:\n",
    "  # train:  boolean\n",
    "  \n",
    "  group_size_dim, unused_input_dim = inputs.shape.dims[-2:] #Last two dimensions -> sequence_length, dense_units\n",
    "\n",
    "  raw_gates = mtf.softmax(mtf.layers.dense(\n",
    "      inputs, experts_dim, use_bias=False,\n",
    "      expert_dims=outer_expert_dims), experts_dim)\n",
    "\n",
    "  # The internals of this function run in float32.\n",
    "  #   bfloat16 seems to reduce quality.\n",
    "  raw_gates = mtf.to_float(raw_gates)\n",
    "\n",
    "  expert_capacity_f = float(expert_capacity_dim.size)\n",
    "\n",
    "  # FIND TOP 2 EXPERTS PER POSITON\n",
    "  # Find the top expert for each position. shape=[batch, group]\n",
    "  index_1, gate_1 = mtf.top_1(raw_gates, experts_dim)\n",
    "  # [batch, group, experts]\n",
    "  mask_1 = mtf.one_hot(index_1, experts_dim, dtype=raw_gates.dtype)\n",
    "  density_1_proxy = raw_gates\n",
    "  if importance is not None:\n",
    "    mask_1 *= mtf.to_float(mtf.equal(importance, 1.0))\n",
    "    gate_1 *= mtf.to_float(mtf.equal(importance, 1.0))\n",
    "    density_1_proxy *= mtf.to_float(mtf.equal(importance, 1.0))\n",
    "  gates_without_top_1 = raw_gates * (1.0 - mask_1)\n",
    "  # [batch, group]\n",
    "  index_2, gate_2 = mtf.top_1(gates_without_top_1, experts_dim)\n",
    "  # [batch, group, experts]\n",
    "  mask_2 = mtf.one_hot(index_2, experts_dim, dtype=raw_gates.dtype)\n",
    "  if importance is not None:\n",
    "    mask_2 *= mtf.to_float(mtf.greater(importance, 0.0))\n",
    "\n",
    "  denom = gate_1 + gate_2 + 1e-9\n",
    "  gate_1 /= denom\n",
    "  gate_2 /= denom\n",
    "\n",
    "  # BALANCING LOSSES\n",
    "  # shape = [batch, experts]\n",
    "  # We want to equalize the fraction of the batch assigned to each expert\n",
    "  density_1 = mtf.reduce_mean(mask_1, reduced_dim=group_size_dim)\n",
    "  # Something continuous that is correlated with what we want to equalize.\n",
    "  density_1_proxy = mtf.reduce_mean(density_1_proxy, reduced_dim=group_size_dim)\n",
    "  density_1 = mtf.Print(\n",
    "      density_1, [mtf.reduce_mean(density_1, output_shape=[experts_dim])],\n",
    "      \"density_1\", summarize=1000)\n",
    "  loss = (mtf.reduce_mean(density_1_proxy * density_1)\n",
    "          * float(experts_dim.size * experts_dim.size))\n",
    "\n",
    "  if hparams.moe_use_second_place_loss:\n",
    "    # Also add a loss to encourage all experts to be used equally also as the\n",
    "    # second-place expert.  Experimentally, this seems to be a wash.\n",
    "    # We want to equalize the fraction of the batch assigned to each expert:\n",
    "    density_2 = mtf.reduce_mean(mask_2, reduced_dim=group_size_dim)\n",
    "    # As a proxy for density_2, we renormalize the raw gates after the top one\n",
    "    # has been removed.\n",
    "    normalized = gates_without_top_1 / (\n",
    "        mtf.reduce_sum(gates_without_top_1, reduced_dim=experts_dim) + 1e-9)\n",
    "    density_2_proxy = mtf.reduce_mean(normalized, reduced_dim=group_size_dim)\n",
    "    loss_2 = (mtf.reduce_mean(density_2_proxy * density_2)\n",
    "              * float(experts_dim.size * experts_dim.size))\n",
    "    loss += loss_2 * 0.5\n",
    "\n",
    "  # Depending on the policy in the hparams, we may drop out some of the\n",
    "  # second-place experts.\n",
    "  policy = (\n",
    "      hparams.moe_second_policy_train if train else\n",
    "      hparams.moe_second_policy_eval)\n",
    "  threshold = (\n",
    "      hparams.moe_second_threshold_train if train else\n",
    "      hparams.moe_second_threshold_eval)\n",
    "  if policy == \"all\":\n",
    "    # Use second-place experts for all examples.\n",
    "    pass\n",
    "  elif policy == \"none\":\n",
    "    # Never use second-place experts for all examples.\n",
    "    mask_2 = mtf.zeros_like(mask_2)\n",
    "  elif policy == \"threshold\":\n",
    "    # Use second-place experts if gate_2 > threshold.\n",
    "    mask_2 *= mtf.to_float(mtf.greater(gate_2, threshold))\n",
    "  elif policy == \"random\":\n",
    "    # Use second-place experts with probablity min(1.0, gate_2 / threshold).\n",
    "    mask_2 *= mtf.to_float(\n",
    "        mtf.less(mtf.random_uniform(gate_2.mesh, gate_2.shape),\n",
    "                 gate_2 / max(threshold, 1e-9)))\n",
    "  else:\n",
    "    raise ValueError(\"Unknown policy %s\" % policy)\n",
    "  mask_2 = mtf.Print(\n",
    "      mask_2, [mtf.reduce_mean(mask_2, output_shape=[experts_dim])],\n",
    "      \"density_2\", summarize=1000)\n",
    "\n",
    "  # COMPUTE ASSIGNMENT TO EXPERTS\n",
    "  # [batch, group, experts]\n",
    "  # This is the position within the expert's mini-batch for this sequence\n",
    "  position_in_expert_1 = mtf.cumsum(\n",
    "      mask_1, group_size_dim, exclusive=True) * mask_1\n",
    "  # Remove the elements that don't fit. [batch, group, experts]\n",
    "  mask_1 *= mtf.to_float(mtf.less(position_in_expert_1, expert_capacity_f))\n",
    "  # [batch, experts]\n",
    "  # How many examples in this sequence go to this expert\n",
    "  mask_1_count = mtf.reduce_sum(mask_1, reduced_dim=group_size_dim)\n",
    "  # [batch, group] - mostly ones, but zeros where something didn't fit\n",
    "  mask_1_flat = mtf.reduce_sum(mask_1, reduced_dim=experts_dim)\n",
    "  # [batch, group]\n",
    "  position_in_expert_1 = mtf.reduce_sum(\n",
    "      position_in_expert_1, reduced_dim=experts_dim)\n",
    "  # Weight assigned to first expert.  [batch, group]\n",
    "  gate_1 *= mask_1_flat\n",
    "\n",
    "  # [batch, group, experts]\n",
    "  position_in_expert_2 = (\n",
    "      mtf.cumsum(mask_2, group_size_dim, exclusive=True) + mask_1_count)\n",
    "  position_in_expert_2 *= mask_2\n",
    "  mask_2 *= mtf.to_float(mtf.less(position_in_expert_2, expert_capacity_f))\n",
    "  # mask_2_count = mtf.reduce_sum(mask_2, reduced_dim=experts_dim)\n",
    "  mask_2_flat = mtf.reduce_sum(mask_2, reduced_dim=experts_dim)\n",
    "  gate_2 *= mask_2_flat\n",
    "  position_in_expert_2 = mtf.reduce_sum(\n",
    "      position_in_expert_2, reduced_dim=experts_dim)\n",
    "\n",
    "  # [batch, group, experts, expert_capacity]\n",
    "  combine_tensor = (\n",
    "      gate_1 * mask_1_flat\n",
    "      * mtf.one_hot(index_1, experts_dim)\n",
    "      * mtf.one_hot(mtf.to_int32(position_in_expert_1), expert_capacity_dim) +\n",
    "      gate_2 * mask_2_flat\n",
    "      * mtf.one_hot(index_2, experts_dim)\n",
    "      * mtf.one_hot(mtf.to_int32(position_in_expert_2), expert_capacity_dim))\n",
    "\n",
    "  combine_tensor = mtf.cast(combine_tensor, inputs.dtype)\n",
    "  loss = mtf.cast(loss, inputs.dtype)\n",
    "\n",
    "  dispatch_tensor = mtf.cast(\n",
    "      mtf.cast(combine_tensor, tf.bool), combine_tensor.dtype)\n",
    "\n",
    "  return dispatch_tensor, combine_tensor, loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
