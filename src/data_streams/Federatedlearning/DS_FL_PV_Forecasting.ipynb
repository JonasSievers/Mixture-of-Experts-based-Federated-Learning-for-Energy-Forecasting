{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import sys  \n",
    "sys.path.append(\"../../\")  \n",
    "from utils.models import *\n",
    "from utils.datahandling import *\n",
    "from utils.modelrunner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants and configurations\n",
    "num_features = 7  # Number of features\n",
    "sequence_length = 25\n",
    "batch_size = 16\n",
    "evaluation_interval = 168\n",
    "mae_threshold = 0.1\n",
    "ks_significance_level = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "num_users = 30\n",
    "num_rounds = 5\n",
    "dataset_name = \"PV\"\n",
    "\n",
    "cwd = os.path.normpath(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))))\n",
    "df = pd.read_csv(cwd+f'/data/3final_data/Final_{dataset_name}_dataset.csv', index_col='Date')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Filter data for a specific period\n",
    "start_date = df.index.min() + pd.DateOffset(years=1)\n",
    "end_date = df.index.max()\n",
    "df = df[(df.index >= start_date) & (df.index < end_date)]\n",
    "\n",
    "df = min_max_scaling(df)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_array = []\n",
    "for idx in range(num_users):\n",
    "    df_array.append(df[[f'User{idx+1}', 'temp', 'rhum', 'wspd', 'PC1', 'hour sin', 'hour cos', f'User{idx+1}_lag_24hrs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metrics=[\n",
    "    tf.keras.metrics.RootMeanSquaredError(), \n",
    "    tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "    tf.keras.metrics.MeanAbsoluteError(),\n",
    "]\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10,mode='min')\n",
    "timing_callback = TimingCallback()\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "callbacks=[early_stopping, timing_callback, custom_callback]\n",
    "\n",
    "custom_objects = {'EinsumLayer': EinsumLayer,'TopKLayer': TopKLayer,'ImportanceRegularizationLayer': ImportanceRegularizationLayer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_compile_model(model_path, model_type, custom_objects=None):\n",
    "    model = tf.keras.models.load_model(model_path, custom_objects=custom_objects, compile=False)\n",
    "    model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=metrics)\n",
    "    return model\n",
    "\n",
    "def calculate_metrics(actual, predictions):\n",
    "    return {\n",
    "        'RMSE': np.sqrt(mean_squared_error(actual, predictions)),\n",
    "        'MAE': mean_absolute_error(actual, predictions),\n",
    "        'MSE': mean_squared_error(actual, predictions)\n",
    "    }\n",
    "\n",
    "def check_concept_drift(actual_interval, predicted_interval, previous_mae, mae_threshold, ks_significance_level, cd_mae_counter, cd_ks_counter):\n",
    "   \n",
    "    current_mae = mean_absolute_error(actual_interval, predicted_interval)\n",
    "    \n",
    "    if not np.isnan(previous_mae) and current_mae > previous_mae * (1 + mae_threshold):\n",
    "        cd_mae_counter += 1\n",
    "\n",
    "    ks_pvalue = ks_2samp(actual_interval, predicted_interval).pvalue\n",
    "    if ks_pvalue < ks_significance_level:\n",
    "        cd_ks_counter += 1 \n",
    "\n",
    "    return cd_mae_counter, cd_ks_counter, current_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.loadtxt(cwd+'/data/3final_data/Clusters_KMeans10_dtw.csv', delimiter=',').astype(int)\n",
    "num_clusters = 10\n",
    "cluster_users = {i: [] for i in range(num_clusters)}\n",
    "\n",
    "# Iterate through each cluster\n",
    "for cluster_number in range(num_clusters):\n",
    "    users_in_cluster = np.where(y == cluster_number)[0] +1\n",
    "    cluster_users[cluster_number] = users_in_cluster\n",
    "cluster_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataFrame to store results\n",
    "columns = ['User', 'Round', 'CD_mae_count', 'CD_ks_count']\n",
    "model_names = ['BiLSTM', 'CNN', 'Transformer', 'soft_dense', 'soft_bilstm', 'topk_dense', 'topk_bilstm']\n",
    "\n",
    "for name in model_names:\n",
    "    columns.extend([f'RMSE_{name}', f'MAE_{name}', f'MSE_{name}'])\n",
    "\n",
    "results_df = pd.DataFrame(columns=columns) \n",
    "\n",
    "\n",
    "#For validation performe multiple rounds\n",
    "for round in range(num_rounds):\n",
    "\n",
    "    # Iterate through the users within a cluster\n",
    "    for cluster_number, users_in_cluster in cluster_users.items():\n",
    "        \n",
    "        #Load and compile the 7 models for the current cluster\n",
    "        model_paths = {\n",
    "            'BiLSTM': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{dataset_name}_Forecasting_Benchmark/wandb/TS_FL_{dataset_name}_global_bilstm_c{cluster_number}_FLround{3}.keras',\n",
    "            'CNN': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{dataset_name}_Forecasting_Benchmark/wandb/TS_FL_{dataset_name}_global_cnn_c{cluster_number}_FLround{3}.keras',\n",
    "            'Transformer': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{dataset_name}_Forecasting_Benchmark/wandb/TS_FL_{dataset_name}_global_transformer_c{cluster_number}_FLround{3}.keras',\n",
    "            'soft_bilstm': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{dataset_name}_Forecasting_Moe/wandb/TS_FL_{dataset_name}_global_soft_bilstm_c{cluster_number}_FLround{3}.keras',\n",
    "            'soft_dense': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{dataset_name}_Forecasting_Moe/wandb/TS_FL_{dataset_name}_global_soft_dense_c{cluster_number}_FLround{3}.keras',\n",
    "            'topk_bilstm': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{dataset_name}_Forecasting_Moe/wandb/TS_FL_{dataset_name}_global_topk_bilstm_c{cluster_number}_FLround{3}.keras',\n",
    "            'topk_dense': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{dataset_name}_Forecasting_Moe/wandb/TS_FL_{dataset_name}_global_topk_dense_c{cluster_number}_FLround{3}.keras'\n",
    "        }\n",
    "        models = {name: load_and_compile_model(path, name, custom_objects) for name, path in model_paths.items()}\n",
    "        \n",
    "        #For each user in the cluster performe predictions\n",
    "        for user_index in users_in_cluster:\n",
    "            \n",
    "            print(\"Round \", round+1, \" / \", num_rounds, \" - User \", user_index, \" in cluster \", cluster_number)\n",
    "            \n",
    "            # Stream data simulation, initialization\n",
    "            user_df = df_array[user_index-1].copy()\n",
    "            stream_data = user_df.values\n",
    "            stream_buffer = []\n",
    "            actual_values = []\n",
    "            cd_mae_counter, cd_ks_counter = 0,0\n",
    "            previous_mae_bilstm = np.NaN\n",
    "            stream_predictions = {name: [] for name in model_names}\n",
    "        \n",
    "            # Enumerate through the data stream\n",
    "            for idx, data in enumerate(stream_data):\n",
    "                \n",
    "                # Buffer: Append data (1 row is one array) to the buffer and pop oldest if sequence_length is surpassed.\n",
    "                stream_buffer.append(data)\n",
    "                \n",
    "                # Check if we have enough data for a batch prediction\n",
    "                if len(stream_buffer) >= batch_size + sequence_length - 1:\n",
    "                    # Prepare batch data for prediction\n",
    "                    batch_data = []\n",
    "                    for i in range(batch_size):\n",
    "                        x_pred = np.array([stream_buffer[i:i+sequence_length-1]])\n",
    "                        batch_data.append(x_pred)              \n",
    "                    \n",
    "                    # Convert list to numpy array for prediction\n",
    "                    batch_data = np.concatenate(batch_data, axis=0)  # Shape becomes (16, 24, 8)\n",
    "\n",
    "                    # Make predictions for each model\n",
    "                    for name, model in models.items():\n",
    "                        predictions = model.predict(batch_data, callbacks=callbacks, verbose=0)\n",
    "                        stream_predictions[name].extend(predictions[:, 0].tolist())\n",
    "\n",
    "                    # Append actual values for the batch\n",
    "                    actual_values.extend([d[0] for d in stream_buffer[-batch_size:]])\n",
    "                    # Clear the processed batch data from buffer\n",
    "                    del stream_buffer[:batch_size]\n",
    "\n",
    "                # Check and evaluate at every evaluation_interval\n",
    "                if (idx + 1) % evaluation_interval == 0 and len(actual_values) >= evaluation_interval:\n",
    "                    actual_interval = actual_values[-evaluation_interval:]\n",
    "                    predicted_interval = stream_predictions['BiLSTM'][-evaluation_interval:]  # Example for BiLSTM\n",
    "\n",
    "                    cd_mae_counter, cd_ks_counter, current_mae = check_concept_drift(\n",
    "                        actual_interval, predicted_interval, previous_mae_bilstm, mae_threshold, ks_significance_level, cd_mae_counter, cd_ks_counter\n",
    "                    )\n",
    "                                    \n",
    "                    previous_mae_bilstm = current_mae   \n",
    "                    \n",
    "            # Calculate metrics for each model and append to DataFrame\n",
    "            if actual_values:\n",
    "                metrics_data = {'User': user_index+1, 'Round': round+1, 'CD_mae_count': cd_mae_counter, 'CD_ks_count': cd_ks_counter}\n",
    "                for name in model_names:\n",
    "                    metrics_data.update({f'{metric}_{name}': value for metric, value in calculate_metrics(actual_values, stream_predictions[name]).items()})\n",
    "                results_df.loc[len(results_df)] = metrics_data\n",
    "            \n",
    "    results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame.from_dict(stream_predictions)\n",
    "\n",
    "predictions_df.to_csv(f'results/Predictions_DS_FL_{dataset_name}_Forecasting.csv')  \n",
    "results_df.to_csv(f'results/Results_DS_FL_{dataset_name}_Forecasting.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting to visualize the results\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(df['User1'][124:500].values, label='Actual Data')\n",
    "plt.plot(stream_predictions[\"soft_bilstm\"][124:500], label='Predictions', linestyle='dashed')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
