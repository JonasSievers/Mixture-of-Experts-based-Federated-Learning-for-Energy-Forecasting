{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import sys  \n",
    "sys.path.append(\"../../../\")  \n",
    "from utils.models import *\n",
    "from utils.datahandling import *\n",
    "from utils.modelrunner import *\n",
    "from utils.federatedrunner import *\n",
    "\n",
    "import wandb\n",
    "import logging\n",
    "logging.getLogger(\"wandb\").setLevel(logging.ERROR)\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "os.environ['WANDB_SILENT'] = 'true'\n",
    "os.environ['WANDB_CONSOLE'] = 'off'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data \n",
    "num_users = 30\n",
    "\n",
    "cwd = os.path.normpath(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))))\n",
    "df = pd.read_csv(cwd+'/data/3final_data/Final_PV_dataset.csv', index_col='Date')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Get the first date from the index\n",
    "start_date = df.index.min()\n",
    "# Calculate the end date as one year from the start date\n",
    "end_date = start_date + pd.DateOffset(years=1)\n",
    "# Filter the dataframe to only include the first year of data\n",
    "df = df[(df.index >= start_date) & (df.index < end_date)]\n",
    "\n",
    "df_array = []\n",
    "for idx in range(num_users):\n",
    "    df_array.append(df[[f'User{idx+1}', 'temp', 'rhum', 'wspd', 'PC1', 'hour sin', 'hour cos', f'User{idx+1}_lag_24hrs']])\n",
    "\n",
    "df_array[0].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "sequence_length = 25\n",
    "batch_size = 16\n",
    "num_features = df_array[0].shape[1]\n",
    "horizon = 1\n",
    "max_epochs = 100\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metrics=[\n",
    "    tf.keras.metrics.RootMeanSquaredError(), \n",
    "    tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "    tf.keras.metrics.MeanAbsoluteError(),\n",
    "]\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10,mode='min')\n",
    "timing_callback = TimingCallback()\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "callbacks=[early_stopping, timing_callback, custom_callback]\n",
    "\n",
    "#BiLSTM\n",
    "lstm_architecture = \"bilstm\"\n",
    "lstm_layers = 2\n",
    "lstm_units = 8\n",
    "lstm_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "lstm_results = pd.DataFrame(columns=['architecture', 'train_time', 'avg_time_epoch', 'mse','mse_std', 'rmse','rmse_std','mape','mape_std','mae','mae_std'])\n",
    "\n",
    "#CNN\n",
    "cnn_architecture = \"CNN_Model\"\n",
    "cnn_layers = 4\n",
    "cnn_kernel_size = 1\n",
    "cnn_filter_size = 8\n",
    "cnn_dense_units = 16\n",
    "cnn_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "cnn_results = pd.DataFrame(columns=['architecture', 'train_time', 'avg_time_epoch', 'mse','mse_std', 'rmse','rmse_std','mape','mape_std','mae','mae_std'])\n",
    "\n",
    "#Transfotransformer_architecture = \"Transformer_ED2_h4_d32\"\n",
    "transformer_layers = 2\n",
    "transformer_heads = 4\n",
    "transformer_dense_units = 16\n",
    "transformer_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "transformer_results = pd.DataFrame(columns=['architecture', 'train_time', 'avg_time_epoch', 'mse','mse_std', 'rmse','rmse_std','mape','mape_std','mae','mae_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train, Validation and Test datasets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "#Create Train, Validation and Test datasets\n",
    "for idx, df in enumerate(df_array):\n",
    "    n = len(df)\n",
    "    train_df = df[0:int(n*0.7)]\n",
    "    val_df = df[int(n*0.7):int(n*0.9)]\n",
    "    test_df = df[int(n*0.9):]\n",
    "\n",
    "    # Min max sclaing\n",
    "    train_df = min_max_scaling(train_df)\n",
    "    val_df = min_max_scaling(val_df)\n",
    "    test_df = min_max_scaling(test_df)\n",
    "\n",
    "    # Sequencing\n",
    "    train_sequences = create_sequences(train_df, sequence_length)\n",
    "    val_sequences = create_sequences(val_df, sequence_length)\n",
    "    test_sequences = create_sequences(test_df, sequence_length)\n",
    "\n",
    "    #Split into feature and label\n",
    "    X_train[f'user{idx+1}'], y_train[f'user{idx+1}'] = prepare_data(train_sequences, batch_size)\n",
    "    X_val[f'user{idx+1}'], y_val[f'user{idx+1}'] = prepare_data(val_sequences, batch_size)\n",
    "    X_test[f'user{idx+1}'], y_test[f'user{idx+1}'] = prepare_data(test_sequences, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated Learning for Benchmark models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_rounds = 3\n",
    "num_rounds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.loadtxt(f'../../../../data/3final_data/Clusters_KMeans10_dtw.csv', delimiter=',').astype(int)\n",
    "num_clusters = 10\n",
    "cluster_users = {i: [] for i in range(num_clusters)}\n",
    "\n",
    "# Iterate through each cluster\n",
    "for cluster_number in range(num_clusters):\n",
    "    users_in_cluster = np.where(y == cluster_number)[0] +1\n",
    "    cluster_users[cluster_number] = users_in_cluster\n",
    "cluster_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bilstm\n",
    "run_federated_benchmark_model(\n",
    "    num_clusters = num_clusters,\n",
    "    federated_rounds = federated_rounds,\n",
    "    cluster_users = cluster_users,\n",
    "    save_path = os.getcwd(),\n",
    "    wb_project_name = \"TS_FL_PV_Forecasting_Benchmark\",\n",
    "    wb_project = \"TS_FL_PV\",\n",
    "    wb_model_name = \"global_bilstm\",\n",
    "    df_array = df_array,\n",
    "    max_epochs = max_epochs,\n",
    "    batch_size = batch_size,\n",
    "    X_train = X_train,\n",
    "    horizon = horizon,\n",
    "    loss = loss,\n",
    "    metrics = metrics,\n",
    "    y_train = y_train,\n",
    "    X_val = X_val,\n",
    "    y_val = y_val,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    callbacks = callbacks,\n",
    "    layers = lstm_layers,\n",
    "    lstm_units = lstm_units\n",
    ")\n",
    " \n",
    "evaluate_federated_benchmark_model(\n",
    "    federated_rounds = federated_rounds,\n",
    "    save_path = os.getcwd(),\n",
    "    wb_project = \"TS_FL_PV\",\n",
    "    wb_model_name = \"global_bilstm\",\n",
    "    cluster_users = cluster_users,\n",
    "    num_rounds = num_rounds,\n",
    "    horizon = horizon,\n",
    "    batch_size = batch_size,\n",
    "    metrics = metrics,\n",
    "    loss = loss,\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    X_val = X_val,\n",
    "    y_val = y_val,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    callbacks = callbacks,\n",
    "    df_array = df_array,\n",
    "    results = lstm_results,\n",
    "    all_results = lstm_all_results,\n",
    "    layers = lstm_layers,\n",
    "    lstm_units = lstm_units,\n",
    "    wb_project_name=\"TS_FL_PV_Forecasting_Benchmark\"\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn\n",
    "run_federated_benchmark_model(\n",
    "    num_clusters = num_clusters,\n",
    "    federated_rounds = federated_rounds,\n",
    "    cluster_users = cluster_users,\n",
    "    save_path = os.getcwd(),\n",
    "    wb_project_name = \"TS_FL_PV_Forecasting_Benchmark\",\n",
    "    wb_project = \"TS_FL_PV\",\n",
    "    wb_model_name = \"global_cnn\",\n",
    "    df_array = df_array,\n",
    "    max_epochs = max_epochs,\n",
    "    batch_size = batch_size,\n",
    "    X_train = X_train,\n",
    "    horizon = horizon,\n",
    "    loss = loss,\n",
    "    metrics = metrics,\n",
    "    y_train = y_train,\n",
    "    X_val = X_val,\n",
    "    y_val = y_val,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    callbacks = callbacks,\n",
    "    layers = cnn_layers,\n",
    "    cnn_filter = cnn_filter_size,\n",
    "    cnn_kernel_size = cnn_kernel_size,\n",
    "    cnn_dense_units=cnn_dense_units\n",
    ")\n",
    "\n",
    "evaluate_federated_benchmark_model(\n",
    "    federated_rounds = federated_rounds,\n",
    "    save_path = os.getcwd(),\n",
    "    wb_project = \"TS_FL_PV\",\n",
    "    wb_model_name = \"global_cnn\",\n",
    "    cluster_users = cluster_users,\n",
    "    num_rounds = num_rounds,\n",
    "    horizon = horizon,\n",
    "    batch_size = batch_size,\n",
    "    metrics = metrics,\n",
    "    loss = loss,\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    X_val = X_val,\n",
    "    y_val = y_val,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    callbacks = callbacks,\n",
    "    df_array = df_array,\n",
    "    results = cnn_results,\n",
    "    all_results = cnn_all_results,\n",
    "    layers = cnn_layers,\n",
    "    cnn_filter = cnn_filter_size,\n",
    "    cnn_kernel_size = cnn_kernel_size,\n",
    "    cnn_dense_units=cnn_dense_units,\n",
    "    wb_project_name=\"TS_FL_PV_Forecasting_Benchmark\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer\n",
    "run_federated_benchmark_model(\n",
    "    num_clusters = num_clusters,\n",
    "    federated_rounds = federated_rounds,\n",
    "    cluster_users = cluster_users,\n",
    "    save_path = os.getcwd(),\n",
    "    wb_project_name = \"TS_FL_PV_Forecasting_Benchmark\",\n",
    "    wb_project = \"TS_FL_PV\",\n",
    "    wb_model_name = \"global_transformer\",\n",
    "    df_array = df_array,\n",
    "    max_epochs = max_epochs,\n",
    "    batch_size = batch_size,\n",
    "    X_train = X_train,\n",
    "    horizon = horizon,\n",
    "    loss = loss,\n",
    "    metrics = metrics,\n",
    "    y_train = y_train,\n",
    "    X_val = X_val,\n",
    "    y_val = y_val,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    callbacks = callbacks,\n",
    "    layers=transformer_layers,\n",
    "    transformer_dense_units= transformer_dense_units,\n",
    "    sequence_length = sequence_length,\n",
    "    transformer_num_features = num_features,\n",
    "    transformer_num_heads = transformer_heads\n",
    ")\n",
    "\n",
    "evaluate_federated_benchmark_model(\n",
    "    federated_rounds = federated_rounds,\n",
    "    save_path = os.getcwd(),\n",
    "    wb_project = \"TS_FL_PV\",\n",
    "    wb_model_name = \"global_transformer\",\n",
    "    cluster_users = cluster_users,\n",
    "    num_rounds = num_rounds,\n",
    "    horizon = horizon,\n",
    "    batch_size = batch_size,\n",
    "    metrics = metrics,\n",
    "    loss = loss,\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    X_val = X_val,\n",
    "    y_val = y_val,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    callbacks = callbacks,\n",
    "    df_array = df_array,\n",
    "    results = transformer_results,###\n",
    "    all_results = transformer_all_results, ###\n",
    "    layers=transformer_layers,\n",
    "    transformer_dense_units= transformer_dense_units,\n",
    "    sequence_length = sequence_length,\n",
    "    transformer_num_features = num_features,\n",
    "    transformer_num_heads = transformer_heads,\n",
    "    wb_project_name=\"TS_FL_PV_Forecasting_Benchmark\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
