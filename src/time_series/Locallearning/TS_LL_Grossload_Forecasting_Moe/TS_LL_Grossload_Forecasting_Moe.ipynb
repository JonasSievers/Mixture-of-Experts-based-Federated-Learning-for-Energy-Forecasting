{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Mixture-of-Experts-based-Federated-Learning-for-Energy-Forecasting\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys  \n",
    "sys.path.append(\"../../../\")  \n",
    "from utils.models import *\n",
    "from utils.datahandling import *\n",
    "from utils.modelrunner import *\n",
    "\n",
    "import wandb\n",
    "import logging\n",
    "logging.getLogger(\"wandb\").setLevel(logging.ERROR)\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "os.environ['WANDB_SILENT'] = 'true'\n",
    "os.environ['WANDB_CONSOLE'] = 'off'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User1</th>\n",
       "      <th>temp</th>\n",
       "      <th>rhum</th>\n",
       "      <th>wspd</th>\n",
       "      <th>PC1</th>\n",
       "      <th>hour sin</th>\n",
       "      <th>hour cos</th>\n",
       "      <th>User1_lag_24hrs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>0.111</td>\n",
       "      <td>2.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.641741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User1  temp  rhum  wspd       PC1  hour sin  hour cos  \\\n",
       "Date                                                                \n",
       "2010-07-02  0.111   2.5  92.0   0.0 -2.641741       0.0       1.0   \n",
       "\n",
       "            User1_lag_24hrs  \n",
       "Date                         \n",
       "2010-07-02            0.125  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data processing\n",
    "\n",
    "#Get data \n",
    "num_users = 30\n",
    "\n",
    "cwd = os.path.normpath(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))))\n",
    "df = pd.read_csv(cwd+'/data/3final_data/Final_Grossload_dataset.csv', index_col='Date')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Get the first date from the index\n",
    "start_date = df.index.min()\n",
    "# Calculate the end date as one year from the start date\n",
    "end_date = start_date + pd.DateOffset(years=1)\n",
    "# Filter the dataframe to only include the first year of data\n",
    "df = df[(df.index >= start_date) & (df.index < end_date)]\n",
    "\n",
    "df_array = []\n",
    "for idx in range(num_users):\n",
    "    df_array.append(df[[f'User{idx+1}', 'temp', 'rhum', 'wspd', 'PC1', 'hour sin', 'hour cos', f'User{idx+1}_lag_24hrs']])\n",
    "\n",
    "df_array[0].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "sequence_length = 25\n",
    "batch_size = 16\n",
    "num_features = df_array[0].shape[1]\n",
    "horizon = 1\n",
    "max_epochs = 100\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metrics=[\n",
    "    tf.keras.metrics.RootMeanSquaredError(), \n",
    "    tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "    tf.keras.metrics.MeanAbsoluteError(),\n",
    "]\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10,mode='min')\n",
    "timing_callback = TimingCallback()\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "callbacks=[early_stopping, timing_callback, custom_callback]\n",
    "\n",
    "#Soft dense MoE\n",
    "dense_smoe_units = 16\n",
    "dense_smoe_expert_units = 8\n",
    "dense_smoe_num_experts = 4\n",
    "dense_smoe_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "dense_smoe_results = pd.DataFrame(columns=['architecture', 'train_time', 'avg_time_epoch', 'mse','mse_std', 'rmse','rmse_std','mape','mape_std','mae','mae_std'])\n",
    "\n",
    "#Soft lstm MoE\n",
    "lstm_smoe_units = 20\n",
    "lstm_smoe_expert_units = 8\n",
    "lstm_smoe_num_experts = 4\n",
    "lstm_smoe_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "lstm_smoe_results = pd.DataFrame(columns=['architecture', 'train_time', 'avg_time_epoch', 'mse','mse_std', 'rmse','rmse_std','mape','mape_std','mae','mae_std'])\n",
    "\n",
    "#topK dense MoE\n",
    "dense_topmoe_units = 16\n",
    "dense_topmoe_num_experts = 5\n",
    "dense_topmoe_top_k = 2\n",
    "dense_topmoe_expert_units = 8\n",
    "dense_topmoe_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "dense_topmoe_results = pd.DataFrame(columns=['architecture', 'train_time', 'avg_time_epoch', 'mse','mse_std', 'rmse','rmse_std','mape','mape_std','mae','mae_std'])\n",
    "\n",
    "#topK lstm MoE\n",
    "lstm_topmoe_units = 20\n",
    "lstm_topmoe_num_experts = 5\n",
    "lstm_topmoe_top_k = 2\n",
    "lstm_topmoe_expert_units = 8\n",
    "lstm_topmoe_all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "lstm_topmoe_results = pd.DataFrame(columns=['architecture', 'train_time', 'avg_time_epoch', 'mse','mse_std', 'rmse','rmse_std','mape','mape_std','mae','mae_std'])\n",
    "\n",
    "#Train, Validation and Test datasets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "#Create Train, Validation and Test datasets\n",
    "for idx, df in enumerate(df_array):\n",
    "    n = len(df)\n",
    "    train_df = df[0:int(n*0.7)]\n",
    "    val_df = df[int(n*0.7):int(n*0.9)]\n",
    "    test_df = df[int(n*0.9):]\n",
    "\n",
    "    # Min max sclaing\n",
    "    train_df = min_max_scaling(train_df)\n",
    "    val_df = min_max_scaling(val_df)\n",
    "    test_df = min_max_scaling(test_df)\n",
    "\n",
    "    # Sequencing\n",
    "    train_sequences = create_sequences(train_df, sequence_length)\n",
    "    val_sequences = create_sequences(val_df, sequence_length)\n",
    "    test_sequences = create_sequences(test_df, sequence_length)\n",
    "\n",
    "    #Split into feature and label\n",
    "    X_train[f'user{idx+1}'], y_train[f'user{idx+1}'] = prepare_data(train_sequences, batch_size)\n",
    "    X_val[f'user{idx+1}'], y_val[f'user{idx+1}'] = prepare_data(val_sequences, batch_size)\n",
    "    X_test[f'user{idx+1}'], y_test[f'user{idx+1}'] = prepare_data(test_sequences, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MoE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----User:  1\n",
      "Round:  0\n",
      "saved model\n",
      "Round:  1\n",
      "saved model\n",
      "Round:  2\n",
      "saved model\n",
      "Round:  3\n",
      "saved model\n",
      "Round:  4\n",
      "saved model\n",
      "-----User:  2\n",
      "Round:  0\n",
      "saved model\n",
      "Round:  1\n",
      "saved model\n",
      "Round:  2\n",
      "saved model\n",
      "Round:  3\n",
      "saved model\n",
      "Round:  4\n",
      "saved model\n",
      "     architecture  train_time  avg_time_epoch       mse   mse_std      rmse  \\\n",
      "0  dense_soft_moe   57.463442        2.307478  0.020255  0.000254  0.142319   \n",
      "\n",
      "   rmse_std          mape     mape_std       mae   mae_std  \n",
      "0  0.000894  40329.085156  6595.362953  0.095338  0.003471  \n"
     ]
    }
   ],
   "source": [
    "run_soft_dense_moe_model (\n",
    "    wb_project_name = \"TS_LL_Grossload_Forecasting_Moe\",\n",
    "    wb_model_name = \"dense_soft_moe\",\n",
    "    wb_project = \"TS_LL_Grossload\",\n",
    "    save_path = os.getcwd(),\n",
    "    df_array = df_array,\n",
    "    max_epochs = max_epochs,\n",
    "    batch_size = batch_size,\n",
    "    X_train = X_train,\n",
    "    horizon = horizon, \n",
    "    dense_smoe_units = dense_smoe_units, \n",
    "    dense_smoe_num_experts = dense_smoe_num_experts, \n",
    "    dense_smoe_expert_units = dense_smoe_expert_units, \n",
    "    metrics = metrics,\n",
    "    loss = loss,\n",
    "    y_train = y_train,\n",
    "    X_val = X_val,\n",
    "    y_val = y_val,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    callbacks = callbacks,\n",
    "    results = dense_smoe_results,\n",
    "    all_results = dense_smoe_all_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----User:  1\n",
      "Round:  0\n",
      "saved model\n",
      "Round:  1\n",
      "saved model\n",
      "-----User:  2\n",
      "Round:  0\n",
      "saved model\n",
      "Round:  1\n",
      "saved model\n",
      "     architecture  train_time  avg_time_epoch       mse   mse_std      rmse  \\\n",
      "0  dense_topk_moe   96.937521         3.57866  0.020847  0.000142  0.144384   \n",
      "\n",
      "   rmse_std          mape     mape_std       mae   mae_std  \n",
      "0  0.000491  38552.113281  4024.465099  0.092996  0.001001  \n"
     ]
    }
   ],
   "source": [
    "run_topk_dense_moe_model(\n",
    "    wb_project_name = \"TS_LL_Grossload_Forecasting_Moe\",\n",
    "    wb_model_name = \"dense_topk_moe\",\n",
    "    wb_project = \"TS_LL_Grossload\",\n",
    "    save_path = os.getcwd(),\n",
    "    df_array = df_array,\n",
    "    max_epochs = max_epochs,\n",
    "    batch_size = batch_size,\n",
    "    X_train = X_train,\n",
    "    horizon = horizon, \n",
    "    dense_topmoe_units = dense_topmoe_units, \n",
    "    dense_topmoe_num_experts = dense_topmoe_num_experts,\n",
    "    dense_topmoe_top_k = dense_topmoe_top_k,\n",
    "    dense_topmoe_expert_units = dense_topmoe_expert_units,\n",
    "    metrics = metrics,\n",
    "    loss = loss,\n",
    "    y_train = y_train,\n",
    "    X_val = X_val,\n",
    "    y_val = y_val,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    callbacks = callbacks,\n",
    "    results = dense_topmoe_results,\n",
    "    all_results = dense_topmoe_all_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----User:  1\n",
      "Round:  0\n",
      "saved model\n",
      "Round:  1\n",
      "saved model\n",
      "-----User:  2\n",
      "Round:  0\n",
      "saved model\n",
      "Round:  1\n",
      "saved model\n",
      "    architecture  train_time  avg_time_epoch       mse   mse_std      rmse  \\\n",
      "0  lstm_soft_moe  141.520762        5.533093  0.020619  0.000523  0.143588   \n",
      "\n",
      "   rmse_std          mape     mape_std       mae   mae_std  \n",
      "0   0.00182  34027.288086  2255.672013  0.099021  0.009578  \n"
     ]
    }
   ],
   "source": [
    "run_soft_lstm_moe_model(\n",
    "    wb_project_name = \"TS_LL_Grossload_Forecasting_Moe\",\n",
    "    wb_model_name = \"lstm_soft_moe\",\n",
    "    wb_project = \"TS_LL_Grossload\",\n",
    "    save_path = os.getcwd(),\n",
    "    df_array = df_array,\n",
    "    max_epochs = max_epochs,\n",
    "    batch_size = batch_size,\n",
    "    X_train = X_train,\n",
    "    horizon = horizon, \n",
    "    lstm_smoe_units = lstm_smoe_units, \n",
    "    lstm_smoe_num_experts = lstm_smoe_num_experts, \n",
    "    lstm_smoe_expert_units = lstm_smoe_expert_units, \n",
    "    metrics = metrics,\n",
    "    loss = loss,\n",
    "    y_train = y_train,\n",
    "    X_val = X_val,\n",
    "    y_val = y_val,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    callbacks = callbacks,\n",
    "    results = lstm_smoe_results,\n",
    "    all_results = lstm_smoe_all_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----User:  1\n",
      "Round:  0\n",
      "saved model\n",
      "Round:  1\n",
      "saved model\n",
      "-----User:  2\n",
      "Round:  0\n",
      "saved model\n",
      "Round:  1\n",
      "saved model\n",
      "    architecture  train_time  avg_time_epoch       mse   mse_std      rmse  \\\n",
      "0  lstm_topk_moe  176.880851        6.659472  0.020223  0.000296  0.142205   \n",
      "\n",
      "   rmse_std          mape     mape_std       mae   mae_std  \n",
      "0   0.00104  34944.970703  13655.19593  0.095166  0.004425  \n"
     ]
    }
   ],
   "source": [
    "run_topk_lstm_moe_model(\n",
    "        wb_project_name = \"TS_LL_Grossload_Forecasting_Moe\",\n",
    "        wb_model_name = \"lstm_topk_moe\",\n",
    "        wb_project = \"TS_LL_Grossload\",\n",
    "        save_path = os.getcwd(),\n",
    "        df_array = df_array,\n",
    "        max_epochs = max_epochs,\n",
    "        batch_size = batch_size,\n",
    "        X_train = X_train,\n",
    "        horizon = horizon,  \n",
    "        lstm_topmoe_units = lstm_topmoe_units, \n",
    "        lstm_topmoe_num_experts = lstm_topmoe_num_experts,\n",
    "        lstm_topmoe_top_k = lstm_topmoe_top_k,\n",
    "        lstm_topmoe_expert_units = lstm_topmoe_expert_units,\n",
    "        metrics = metrics,\n",
    "        loss = loss,\n",
    "        y_train = y_train,\n",
    "        X_val = X_val,\n",
    "        y_val = y_val,\n",
    "        X_test = X_test,\n",
    "        y_test = y_test,\n",
    "        callbacks = callbacks,\n",
    "        results = lstm_topmoe_results,\n",
    "        all_results = lstm_topmoe_all_results,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
