{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rs1044\\Documents\\GitHub\\Mixture-of-Experts-based-Federated-Learning-for-Energy-Forecasting\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import sys  \n",
    "sys.path.append(\"../../\")  \n",
    "from utils.models import *\n",
    "from utils.datahandling import *\n",
    "from utils.modelrunner import *\n",
    "\n",
    "import wandb\n",
    "import logging\n",
    "logging.getLogger(\"wandb\").setLevel(logging.ERROR)\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "os.environ['WANDB_SILENT'] = 'true'\n",
    "os.environ['WANDB_CONSOLE'] = 'off'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for users 31-60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 25\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data \n",
    "num_users = 30\n",
    "start_user_idx = 31\n",
    "\n",
    "cwd = os.path.normpath(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))))\n",
    "df = pd.read_csv(cwd+'/data/3final_data/Final_Grossload_dataset.csv', index_col='Date')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Get the first date from the index\n",
    "start_date = df.index.min()\n",
    "# Calculate the end date as one year from the start date\n",
    "end_date = start_date + pd.DateOffset(years=1)\n",
    "# Filter the dataframe to only include the first year of data\n",
    "df = df[(df.index >= start_date) & (df.index < end_date)]\n",
    "\n",
    "df_array = []\n",
    "for idx in range(start_user_idx, start_user_idx + num_users):\n",
    "    df_array.append(df[[f'User{idx}', 'temp', 'rhum', 'wspd', 'PC1', 'hour sin', 'hour cos', f'User{idx}_lag_24hrs']])\n",
    "\n",
    "#Train, Validation and Test datasets\n",
    "#X_train, y_train, X_val, y_val, X_test, y_test = {}, {}, {}, {}, {}, {}\n",
    "X_test, y_test = {}, {}\n",
    "\n",
    "#Create Train, Validation and Test datasets\n",
    "for idx, df in enumerate(df_array):\n",
    "    n = len(df)\n",
    "    test_df = df[0:]\n",
    "\n",
    "    # Min max sclaing\n",
    "    test_df = min_max_scaling(test_df)\n",
    "\n",
    "    # Sequencing\n",
    "    test_sequences = create_sequences(test_df, sequence_length)\n",
    "\n",
    "    #Split into feature and label\n",
    "    X_test[f'user{idx+31}'], y_test[f'user{idx+31}'] = prepare_data(test_sequences, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "num_features = df_array[0].shape[1]\n",
    "horizon = 1\n",
    "max_epochs = 100\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metrics=[\n",
    "    tf.keras.metrics.RootMeanSquaredError(), \n",
    "    tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "    tf.keras.metrics.MeanAbsoluteError(),\n",
    "]\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10,mode='min')\n",
    "timing_callback = TimingCallback()\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "callbacks=[early_stopping, timing_callback, custom_callback]\n",
    "\n",
    "def load_and_compile_model(model_path, model_type, custom_objects=None):\n",
    "    model = tf.keras.models.load_model(model_path, custom_objects=custom_objects, compile=False)\n",
    "    model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([ 7, 14, 18, 22, 23, 25, 29], dtype=int64),\n",
       " 1: array([6], dtype=int64),\n",
       " 2: array([ 3,  4,  9, 13, 15, 19, 20, 30], dtype=int64),\n",
       " 3: array([1], dtype=int64),\n",
       " 4: array([21], dtype=int64),\n",
       " 5: array([ 2, 28], dtype=int64),\n",
       " 6: array([ 5, 10, 11, 12, 24, 26, 27], dtype=int64),\n",
       " 7: array([8], dtype=int64),\n",
       " 8: array([17], dtype=int64),\n",
       " 9: array([16], dtype=int64)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.loadtxt(f'../../../data/3final_data/Clusters_KMeans10_dtw.csv', delimiter=',').astype(int)\n",
    "num_clusters = 10\n",
    "cluster_users = {i: [] for i in range(num_clusters)}\n",
    "\n",
    "# Iterate through each cluster\n",
    "for cluster_number in range(num_clusters):\n",
    "    users_in_cluster = np.where(y == cluster_number)[0] +1\n",
    "    cluster_users[cluster_number] = users_in_cluster\n",
    "cluster_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Totalload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataFrame to store results\n",
    "columns = ['User', 'Round']\n",
    "model_names = ['BiLSTM', 'CNN', 'Transformer', 'soft_dense', 'soft_bilstm', 'topk_dense', 'topk_bilstm']\n",
    "\n",
    "for name in model_names:\n",
    "    columns.extend([f'RMSE_LL_{name}', f'MAE_LL_{name}', f'MSE_LL_{name}'])  # Local Learning Metrics\n",
    "    columns.extend([f'RMSE_FL_{name}', f'MAE_FL_{name}', f'MSE_FL_{name}'])  # Federated Learning Metrics\n",
    "\n",
    "results_df_totalload = pd.DataFrame(columns=columns)\n",
    "\n",
    "data = \"Totalload\"\n",
    "user=1\n",
    "cluster=4\n",
    "#Load models\n",
    "custom_objects = {'EinsumLayer': EinsumLayer,'TopKLayer': TopKLayer,'ImportanceRegularizationLayer': ImportanceRegularizationLayer}\n",
    "local_model_paths = {\n",
    "            'LL_BiLSTM': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Benchmark/wandb/TS_LL_{data}_bilstm_u{user}_rd{1}.keras',\n",
    "            'LL_CNN': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Benchmark/wandb/TS_LL_{data}_cnn_u{user}_rd{1}.keras',\n",
    "            'LL_Transformer': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Benchmark/wandb/TS_LL_{data}_transformer_u{user}_rd{1}.keras',\n",
    "            'LL_soft_bilstm': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Moe/wandb/TS_LL_{data}_lstm_soft_moe_u{user}_rd{1}.keras',\n",
    "            'LL_soft_dense': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Moe/wandb/TS_LL_{data}_dense_soft_moe_u{user}_rd{1}.keras',\n",
    "            'LL_topk_bilstm': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Moe/wandb/TS_LL_{data}_lstm_topk_moe_u{user}_rd{1}.keras',\n",
    "            'LL_topk_dense': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Moe/wandb/TS_LL_{data}_dense_topk_moe_u{user}_rd{1}.keras'\n",
    "        }\n",
    "\n",
    "#Federated learning\n",
    "federated_model_paths = {\n",
    "            'FL_BiLSTM': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Benchmark/wandb/TS_FL_{data}_global_bilstm_c{cluster}_FLround3.keras',\n",
    "            'FL_CNN': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Benchmark/wandb/TS_FL_{data}_global_cnn_c{cluster}_FLround3.keras',\n",
    "            'FL_Transformer': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Benchmark/wandb/TS_FL_{data}_global_transformer_c{cluster}_FLround3.keras',\n",
    "            'FL_soft_bilstm': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Moe/wandb/TS_FL_{data}_global_soft_bilstm_c{cluster}_FLround3.keras',\n",
    "            'FL_soft_dense': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Moe/wandb/TS_FL_{data}_global_soft_dense_c{cluster}_FLround3.keras',\n",
    "            'FL_topk_bilstm': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Moe/wandb/TS_FL_{data}_global_topk_bilstm_c{cluster}_FLround3.keras',\n",
    "            'FL_topk_dense': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Moe/wandb/TS_FL_{data}_global_topk_dense_c{cluster}_FLround3.keras'\n",
    "        }\n",
    "\n",
    "local_models = {name: load_and_compile_model(path, name, custom_objects) for name, path in local_model_paths.items()}\n",
    "federated_models = {name: load_and_compile_model(path, name, custom_objects) for name, path in federated_model_paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.104589336391153\n",
      "0.09406853377305228\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_models(models, user_idx, X_test_user, y_test_user):\n",
    "    user_metrics = {}\n",
    "    for model_name, model in models.items():\n",
    "        test_loss, test_rmse, test_mape, test_mae = model.evaluate(X_test_user, y_test_user, batch_size=batch_size, verbose=0)\n",
    "        user_metrics[f'RMSE_{model_name}'] = test_rmse\n",
    "        user_metrics[f'MAE_{model_name}'] = test_mae\n",
    "        user_metrics[f'MSE_{model_name}'] = test_loss\n",
    "    return user_metrics\n",
    "\n",
    "# Iterate over each user\n",
    "for user_idx in range(31, 60):\n",
    "    \n",
    "    # Get the test data for the current user\n",
    "    X_test_user = X_test[f'user{user_idx}']\n",
    "    y_test_user = y_test[f'user{user_idx}']\n",
    "    \n",
    "    # Evaluate local models\n",
    "    local_metrics = evaluate_models(local_models, user_idx, X_test_user, y_test_user)\n",
    "    \n",
    "    # Evaluate federated models\n",
    "    federated_metrics = evaluate_models(federated_models, user_idx, X_test_user, y_test_user)\n",
    "    \n",
    "    # Combine metrics and create a new row\n",
    "    new_row = {'User': user_idx, 'Round': 1, **local_metrics, **federated_metrics}\n",
    "\n",
    "    # Add the new row to the DataFrame\n",
    "    results_df_totalload.loc[len(results_df_totalload)] = new_row\n",
    "\n",
    "print(results_df_totalload[\"RMSE_LL_BiLSTM\"].mean())\n",
    "print(results_df_totalload[\"RMSE_FL_soft_bilstm\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark Mean: \n",
      "LSTM:  0.1046  , Transformer:  0.1369  , CNN:  0.1383\n",
      "MoE: \n",
      "Soft Dense:  0.0994 Topk Dense:  0.097\n",
      "Soft LSTM:  0.0941 Topk LSTM:  0.0988\n"
     ]
    }
   ],
   "source": [
    "print(\"Benchmark Mean: \")\n",
    "print(\"LSTM: \", results_df_totalload[\"RMSE_LL_BiLSTM\"].mean().round(4), \" , Transformer: \", results_df_totalload[\"RMSE_LL_Transformer\"].mean().round(4), \" , CNN: \", results_df_totalload[\"RMSE_LL_CNN\"].mean().round(4))\n",
    "print(\"MoE: \")\n",
    "print(\"Soft Dense: \", results_df_totalload[\"RMSE_FL_soft_dense\"].mean().round(4), \"Topk Dense: \", results_df_totalload[\"RMSE_FL_topk_dense\"].mean().round(4))\n",
    "print(\"Soft LSTM: \", results_df_totalload[\"RMSE_FL_soft_bilstm\"].mean().round(4), \"Topk LSTM: \", results_df_totalload[\"RMSE_FL_topk_bilstm\"].mean().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark Std: \n",
      "LSTM:  0.0228  , Transformer:  0.0256  , CNN:  0.0152\n",
      "MoE: \n",
      "Soft Dense:  0.0232 Topk Dense:  0.0234\n",
      "Soft LSTM:  0.0237 Topk LSTM:  0.0213\n"
     ]
    }
   ],
   "source": [
    "print(\"Benchmark Std: \")\n",
    "print(\"LSTM: \", results_df_totalload[\"RMSE_LL_BiLSTM\"].std().round(4), \" , Transformer: \", results_df_totalload[\"RMSE_LL_Transformer\"].std().round(4), \" , CNN: \", results_df_totalload[\"RMSE_LL_CNN\"].std().round(4))\n",
    "print(\"MoE: \")\n",
    "print(\"Soft Dense: \", results_df_totalload[\"RMSE_FL_soft_dense\"].std().round(4), \"Topk Dense: \", results_df_totalload[\"RMSE_FL_topk_dense\"].std().round(4))\n",
    "print(\"Soft LSTM: \", results_df_totalload[\"RMSE_FL_soft_bilstm\"].std().round(4), \"Topk LSTM: \", results_df_totalload[\"RMSE_FL_topk_bilstm\"].std().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataFrame to store results\n",
    "columns = ['User', 'Round']\n",
    "model_names = ['BiLSTM', 'CNN', 'Transformer', 'soft_dense', 'soft_bilstm', 'topk_dense', 'topk_bilstm']\n",
    "\n",
    "for name in model_names:\n",
    "    columns.extend([f'RMSE_LL_{name}', f'MAE_LL_{name}', f'MSE_LL_{name}'])  # Local Learning Metrics\n",
    "    columns.extend([f'RMSE_FL_{name}', f'MAE_FL_{name}', f'MSE_FL_{name}'])  # Federated Learning Metrics\n",
    "\n",
    "results_df_pv = pd.DataFrame(columns=columns)\n",
    "\n",
    "data = \"PV\"\n",
    "user=1\n",
    "cluster=4\n",
    "\n",
    "#Load models\n",
    "custom_objects = {'EinsumLayer': EinsumLayer,'TopKLayer': TopKLayer,'ImportanceRegularizationLayer': ImportanceRegularizationLayer}\n",
    "local_model_paths = {\n",
    "            'LL_BiLSTM': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Benchmark/wandb/TS_LL_{data}_bilstm_u{user}_rd{1}.keras',\n",
    "            'LL_CNN': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Benchmark/wandb/TS_LL_{data}_cnn_u{user}_rd{1}.keras',\n",
    "            'LL_Transformer': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Benchmark/wandb/TS_LL_{data}_transformer_u{user}_rd{1}.keras',\n",
    "            'LL_soft_bilstm': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Moe/wandb/TS_LL_{data}_lstm_soft_moe_u{user}_rd{1}.keras',\n",
    "            'LL_soft_dense': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Moe/wandb/TS_LL_{data}_dense_soft_moe_u{user}_rd{1}.keras',\n",
    "            'LL_topk_bilstm': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Moe/wandb/TS_LL_{data}_lstm_topk_moe_u{user}_rd{1}.keras',\n",
    "            'LL_topk_dense': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Moe/wandb/TS_LL_{data}_dense_topk_moe_u{user}_rd{1}.keras'\n",
    "        }\n",
    "\n",
    "#Federated learning\n",
    "federated_model_paths = {\n",
    "            'FL_BiLSTM': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Benchmark/wandb/TS_FL_{data}_global_bilstm_c{cluster}_FLround3.keras',\n",
    "            'FL_CNN': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Benchmark/wandb/TS_FL_{data}_global_cnn_c{cluster}_FLround3.keras',\n",
    "            'FL_Transformer': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Benchmark/wandb/TS_FL_{data}_global_transformer_c{cluster}_FLround3.keras',\n",
    "            'FL_soft_bilstm': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Moe/wandb/TS_FL_{data}_global_soft_bilstm_c{cluster}_FLround3.keras',\n",
    "            'FL_soft_dense': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Moe/wandb/TS_FL_{data}_global_soft_dense_c{cluster}_FLround3.keras',\n",
    "            'FL_topk_bilstm': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Moe/wandb/TS_FL_{data}_global_topk_bilstm_c{cluster}_FLround3.keras',\n",
    "            'FL_topk_dense': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Moe/wandb/TS_FL_{data}_global_topk_dense_c{cluster}_FLround3.keras'\n",
    "        }\n",
    "\n",
    "local_models = {name: load_and_compile_model(path, name, custom_objects) for name, path in local_model_paths.items()}\n",
    "federated_models = {name: load_and_compile_model(path, name, custom_objects) for name, path in federated_model_paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1524841538790999\n",
      "0.1125966798642586\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_models(models, user_idx, X_test_user, y_test_user):\n",
    "    user_metrics = {}\n",
    "    for model_name, model in models.items():\n",
    "        test_loss, test_rmse, test_mape, test_mae = model.evaluate(X_test_user, y_test_user, batch_size=batch_size, verbose=0)\n",
    "        user_metrics[f'RMSE_{model_name}'] = test_rmse\n",
    "        user_metrics[f'MAE_{model_name}'] = test_mae\n",
    "        user_metrics[f'MSE_{model_name}'] = test_loss\n",
    "    return user_metrics\n",
    "\n",
    "# Iterate over each user\n",
    "for user_idx in range(31, 60):\n",
    "    \n",
    "    # Get the test data for the current user\n",
    "    X_test_user = X_test[f'user{user_idx}']\n",
    "    y_test_user = y_test[f'user{user_idx}']\n",
    "    \n",
    "    # Evaluate local models\n",
    "    local_metrics = evaluate_models(local_models, user_idx, X_test_user, y_test_user)\n",
    "    \n",
    "    # Evaluate federated models\n",
    "    federated_metrics = evaluate_models(federated_models, user_idx, X_test_user, y_test_user)\n",
    "    \n",
    "    # Combine metrics and create a new row\n",
    "    new_row = {'User': user_idx, 'Round': 1, **local_metrics, **federated_metrics}\n",
    "\n",
    "    # Add the new row to the DataFrame\n",
    "    results_df_pv.loc[len(results_df_pv)] = new_row\n",
    "\n",
    "print(results_df_pv[\"RMSE_LL_BiLSTM\"].mean())\n",
    "print(results_df_pv[\"RMSE_FL_soft_bilstm\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark: \n",
      "LSTM:  0.1525  , Transformer:  0.149  , CNN:  0.1288\n",
      "MoE: \n",
      "Soft Dense:  0.1208 Topk Dense:  0.1177\n",
      "Soft LSTM:  0.1126 Topk LSTM:  0.1189\n"
     ]
    }
   ],
   "source": [
    "print(\"Benchmark: \")\n",
    "print(\"LSTM: \", results_df_pv[\"RMSE_LL_BiLSTM\"].mean().round(4), \" , Transformer: \", results_df_pv[\"RMSE_LL_Transformer\"].mean().round(4), \" , CNN: \", results_df_pv[\"RMSE_LL_CNN\"].mean().round(4))\n",
    "print(\"MoE: \")\n",
    "print(\"Soft Dense: \", results_df_pv[\"RMSE_FL_soft_dense\"].mean().round(4), \"Topk Dense: \", results_df_pv[\"RMSE_FL_topk_dense\"].mean().round(4))\n",
    "print(\"Soft LSTM: \", results_df_pv[\"RMSE_FL_soft_bilstm\"].mean().round(4), \"Topk LSTM: \", results_df_pv[\"RMSE_FL_topk_bilstm\"].mean().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark Std: \n",
      "LSTM:  0.0403  , Transformer:  0.0414  , CNN:  0.017\n",
      "MoE: \n",
      "Soft Dense:  0.0308 Topk Dense:  0.0321\n",
      "Soft LSTM:  0.0273 Topk LSTM:  0.0297\n"
     ]
    }
   ],
   "source": [
    "print(\"Benchmark Std: \")\n",
    "print(\"LSTM: \", results_df_pv[\"RMSE_LL_BiLSTM\"].std().round(4), \" , Transformer: \", results_df_pv[\"RMSE_LL_Transformer\"].std().round(4), \" , CNN: \", results_df_pv[\"RMSE_LL_CNN\"].std().round(4))\n",
    "print(\"MoE: \")\n",
    "print(\"Soft Dense: \", results_df_pv[\"RMSE_FL_soft_dense\"].std().round(4), \"Topk Dense: \", results_df_pv[\"RMSE_FL_topk_dense\"].std().round(4))\n",
    "print(\"Soft LSTM: \", results_df_pv[\"RMSE_FL_soft_bilstm\"].std().round(4), \"Topk LSTM: \", results_df_pv[\"RMSE_FL_topk_bilstm\"].std().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prosumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataFrame to store results\n",
    "columns = ['User', 'Round']\n",
    "model_names = ['BiLSTM', 'CNN', 'Transformer', 'soft_dense', 'soft_bilstm', 'topk_dense', 'topk_bilstm']\n",
    "\n",
    "for name in model_names:\n",
    "    columns.extend([f'RMSE_LL_{name}', f'MAE_LL_{name}', f'MSE_LL_{name}'])  # Local Learning Metrics\n",
    "    columns.extend([f'RMSE_FL_{name}', f'MAE_FL_{name}', f'MSE_FL_{name}'])  # Federated Learning Metrics\n",
    "\n",
    "results_df_prosumption = pd.DataFrame(columns=columns)\n",
    "\n",
    "data = \"Prosumption\"\n",
    "user=1\n",
    "cluster=4\n",
    "#Load models\n",
    "custom_objects = {'EinsumLayer': EinsumLayer,'TopKLayer': TopKLayer,'ImportanceRegularizationLayer': ImportanceRegularizationLayer}\n",
    "local_model_paths = {\n",
    "            'LL_BiLSTM': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Benchmark/wandb/TS_LL_{data}_bilstm_u{user}_rd{1}.keras',\n",
    "            'LL_CNN': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Benchmark/wandb/TS_LL_{data}_cnn_u{user}_rd{1}.keras',\n",
    "            'LL_Transformer': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Benchmark/wandb/TS_LL_{data}_transformer_u{user}_rd{1}.keras',\n",
    "            'LL_soft_bilstm': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Moe/wandb/TS_LL_{data}_lstm_soft_moe_u{user}_rd{1}.keras',\n",
    "            'LL_soft_dense': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Moe/wandb/TS_LL_{data}_dense_soft_moe_u{user}_rd{1}.keras',\n",
    "            'LL_topk_bilstm': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Moe/wandb/TS_LL_{data}_lstm_topk_moe_u{user}_rd{1}.keras',\n",
    "            'LL_topk_dense': f'{cwd}/src/time_series/Locallearning/TS_LL_{data}_Forecasting_Moe/wandb/TS_LL_{data}_dense_topk_moe_u{user}_rd{1}.keras'\n",
    "        }\n",
    "\n",
    "#Federated learning\n",
    "federated_model_paths = {\n",
    "            'FL_BiLSTM': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Benchmark/wandb/TS_FL_{data}_global_bilstm_c{cluster}_FLround3.keras',\n",
    "            'FL_CNN': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Benchmark/wandb/TS_FL_{data}_global_cnn_c{cluster}_FLround3.keras',\n",
    "            'FL_Transformer': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Benchmark/wandb/TS_FL_{data}_global_transformer_c{cluster}_FLround3.keras',\n",
    "            'FL_soft_bilstm': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Moe/wandb/TS_FL_{data}_global_soft_bilstm_c{cluster}_FLround3.keras',\n",
    "            'FL_soft_dense': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Moe/wandb/TS_FL_{data}_global_soft_dense_c{cluster}_FLround3.keras',\n",
    "            'FL_topk_bilstm': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Moe/wandb/TS_FL_{data}_global_topk_bilstm_c{cluster}_FLround3.keras',\n",
    "            'FL_topk_dense': f'{cwd}/src/time_series/Federatedlearning/TS_FL_{data}_Forecasting_Moe/wandb/TS_FL_{data}_global_topk_dense_c{cluster}_FLround3.keras'\n",
    "        }\n",
    "\n",
    "local_models = {name: load_and_compile_model(path, name, custom_objects) for name, path in local_model_paths.items()}\n",
    "federated_models = {name: load_and_compile_model(path, name, custom_objects) for name, path in federated_model_paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21469462020643826\n",
      "0.10607381113644304\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_models(models, user_idx, X_test_user, y_test_user):\n",
    "    user_metrics = {}\n",
    "    for model_name, model in models.items():\n",
    "        test_loss, test_rmse, test_mape, test_mae = model.evaluate(X_test_user, y_test_user, batch_size=batch_size, verbose=0)\n",
    "        user_metrics[f'RMSE_{model_name}'] = test_rmse\n",
    "        user_metrics[f'MAE_{model_name}'] = test_mae\n",
    "        user_metrics[f'MSE_{model_name}'] = test_loss\n",
    "    return user_metrics\n",
    "\n",
    "# Iterate over each user\n",
    "for user_idx in range(31, 60):\n",
    "    \n",
    "    # Get the test data for the current user\n",
    "    X_test_user = X_test[f'user{user_idx}']\n",
    "    y_test_user = y_test[f'user{user_idx}']\n",
    "    \n",
    "    # Evaluate local models\n",
    "    local_metrics = evaluate_models(local_models, user_idx, X_test_user, y_test_user)\n",
    "    \n",
    "    # Evaluate federated models\n",
    "    federated_metrics = evaluate_models(federated_models, user_idx, X_test_user, y_test_user)\n",
    "    \n",
    "    # Combine metrics and create a new row\n",
    "    new_row = {'User': user_idx, 'Round': 1, **local_metrics, **federated_metrics}\n",
    "\n",
    "    # Add the new row to the DataFrame\n",
    "    results_df_prosumption.loc[len(results_df_prosumption)] = new_row\n",
    "\n",
    "print(results_df_prosumption[\"RMSE_LL_BiLSTM\"].mean())\n",
    "print(results_df_prosumption[\"RMSE_FL_soft_bilstm\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark: \n",
      "LSTM:  0.2147  , Transformer:  0.1819  , CNN:  0.3384\n",
      "MoE: \n",
      "Soft Dense:  0.1141 Topk Dense:  0.115\n",
      "Soft LSTM:  0.1061 Topk LSTM:  0.1147\n"
     ]
    }
   ],
   "source": [
    "print(\"Benchmark: \")\n",
    "print(\"LSTM: \", results_df_prosumption[\"RMSE_LL_BiLSTM\"].mean().round(4), \" , Transformer: \", results_df_prosumption[\"RMSE_LL_Transformer\"].mean().round(4), \" , CNN: \", results_df_prosumption[\"RMSE_LL_CNN\"].mean().round(4))\n",
    "print(\"MoE: \")\n",
    "print(\"Soft Dense: \", results_df_prosumption[\"RMSE_FL_soft_dense\"].mean().round(4), \"Topk Dense: \", results_df_prosumption[\"RMSE_FL_topk_dense\"].mean().round(4))\n",
    "print(\"Soft LSTM: \", results_df_prosumption[\"RMSE_FL_soft_bilstm\"].mean().round(4), \"Topk LSTM: \", results_df_prosumption[\"RMSE_FL_topk_bilstm\"].mean().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark Std: \n",
      "LSTM:  0.0137  , Transformer:  0.0327  , CNN:  0.0328\n",
      "MoE: \n",
      "Soft Dense:  0.0326 Topk Dense:  0.0327\n",
      "Soft LSTM:  0.0345 Topk LSTM:  0.0322\n"
     ]
    }
   ],
   "source": [
    "print(\"Benchmark Std: \")\n",
    "print(\"LSTM: \", results_df_prosumption[\"RMSE_LL_BiLSTM\"].std().round(4), \" , Transformer: \", results_df_prosumption[\"RMSE_LL_Transformer\"].std().round(4), \" , CNN: \", results_df_prosumption[\"RMSE_LL_CNN\"].std().round(4))\n",
    "print(\"MoE: \")\n",
    "print(\"Soft Dense: \", results_df_prosumption[\"RMSE_FL_soft_dense\"].std().round(4), \"Topk Dense: \", results_df_prosumption[\"RMSE_FL_topk_dense\"].std().round(4))\n",
    "print(\"Soft LSTM: \", results_df_prosumption[\"RMSE_FL_soft_bilstm\"].std().round(4), \"Topk LSTM: \", results_df_prosumption[\"RMSE_FL_topk_bilstm\"].std().round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
